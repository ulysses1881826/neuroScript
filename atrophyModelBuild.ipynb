{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "import torch\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense\n",
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型想法：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ./csvFiles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvPath = \"/home/ubuntu/Desktop/ADNI_MRI_Image/neuroScript/csvFiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "volner = pd.read_csv(os.path.join(csvPath,\"Freesurfer_S1200_Extensively_Processed_fMRI_Data.csv\"))\n",
    "volner = volner.dropna()\n",
    "# MCI_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"MCI_amyloid_pos_freeStatsOut.csv\"))\n",
    "MCI_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"MCI_all_freeStatsOut.csv\"))\n",
    "MCI_freesurfer_Out = MCI_freesurfer_Out.dropna()\n",
    "AD_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"AD_all_freeStatsOut.csv\"))\n",
    "AD_freesurfer_Out = AD_freesurfer_Out.dropna()\n",
    "CN_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"CN_all_freeStatsOut.csv\"))\n",
    "CN_freesurfer_Out = CN_freesurfer_Out.dropna()\n",
    "volner['Label'] = 0\n",
    "AD_freesurfer_Out['Label'] = 1\n",
    "MCI_freesurfer_Out['Label'] = 1\n",
    "CN_freesurfer_Out['Label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "volAndCN_data = pd.concat([CN_freesurfer_Out, volner], axis=0, sort=False)\n",
    "# volAndCN_data = volAndCN_data.dropna()\n",
    "volAndMCI_data = pd.concat([MCI_freesurfer_Out, volner], axis=0, sort=False)\n",
    "# volAndMCI_data = volAndMCI_data.dropna()\n",
    "volAndAD_data = pd.concat([AD_freesurfer_Out, volner], axis=0, sort=False)\n",
    "# volAndAD_data = volAndAD_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Subject</th>\n",
       "      <th>FS_L_ThalamusProper_Vol</th>\n",
       "      <th>FS_L_Caudate_Vol</th>\n",
       "      <th>FS_L_Putamen_Vol</th>\n",
       "      <th>FS_L_Pallidum_Vol</th>\n",
       "      <th>FS_L_Hippo_Vol</th>\n",
       "      <th>FS_L_Amygdala_Vol</th>\n",
       "      <th>FS_L_AccumbensArea_Vol</th>\n",
       "      <th>FS_R_ThalamusProper_Vol</th>\n",
       "      <th>...</th>\n",
       "      <th>FS_L_WM_Hypointens_Vol</th>\n",
       "      <th>FS_R_WM_Hypointens_Vol</th>\n",
       "      <th>FS_L_Non-WM_Hypointens_Vol</th>\n",
       "      <th>FS_R_Non-WM_Hypointens_Vol</th>\n",
       "      <th>FS_OpticChiasm_Vol</th>\n",
       "      <th>FS_CC_Posterior_Vol</th>\n",
       "      <th>FS_CC_MidPosterior_Vol</th>\n",
       "      <th>FS_CC_Central_Vol</th>\n",
       "      <th>FS_CC_MidAnterior_Vol</th>\n",
       "      <th>FS_CC_Anterior_Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>037_S_4071</td>\n",
       "      <td>7524.5</td>\n",
       "      <td>4313.9</td>\n",
       "      <td>4709.2</td>\n",
       "      <td>2411.9</td>\n",
       "      <td>4141.2</td>\n",
       "      <td>1453.2</td>\n",
       "      <td>303.6</td>\n",
       "      <td>7778.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>018_S_4400</td>\n",
       "      <td>7040.7</td>\n",
       "      <td>2889.0</td>\n",
       "      <td>4192.5</td>\n",
       "      <td>1805.1</td>\n",
       "      <td>3917.6</td>\n",
       "      <td>1660.1</td>\n",
       "      <td>390.7</td>\n",
       "      <td>6533.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>029_S_4290</td>\n",
       "      <td>6034.1</td>\n",
       "      <td>3711.6</td>\n",
       "      <td>4222.0</td>\n",
       "      <td>2110.8</td>\n",
       "      <td>3113.6</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>439.5</td>\n",
       "      <td>5530.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>029_S_4652</td>\n",
       "      <td>6008.3</td>\n",
       "      <td>2884.1</td>\n",
       "      <td>3715.7</td>\n",
       "      <td>1612.7</td>\n",
       "      <td>3478.3</td>\n",
       "      <td>1190.9</td>\n",
       "      <td>457.1</td>\n",
       "      <td>5293.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>031_S_4474</td>\n",
       "      <td>6948.1</td>\n",
       "      <td>3291.7</td>\n",
       "      <td>3953.5</td>\n",
       "      <td>1728.6</td>\n",
       "      <td>3193.5</td>\n",
       "      <td>1227.4</td>\n",
       "      <td>469.7</td>\n",
       "      <td>6342.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>992774</td>\n",
       "      <td>8416.0</td>\n",
       "      <td>3756.0</td>\n",
       "      <td>5080.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>1473.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>6862.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>1004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>NaN</td>\n",
       "      <td>993675</td>\n",
       "      <td>7477.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>4874.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>4571.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>6879.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>NaN</td>\n",
       "      <td>994273</td>\n",
       "      <td>8416.0</td>\n",
       "      <td>4236.0</td>\n",
       "      <td>5961.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>4159.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>8228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>NaN</td>\n",
       "      <td>995174</td>\n",
       "      <td>9334.0</td>\n",
       "      <td>4546.0</td>\n",
       "      <td>6769.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>4616.0</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>8032.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>NaN</td>\n",
       "      <td>996782</td>\n",
       "      <td>8793.0</td>\n",
       "      <td>4432.0</td>\n",
       "      <td>6086.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>5133.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>7665.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>938.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     Subject  FS_L_ThalamusProper_Vol  FS_L_Caudate_Vol  \\\n",
       "0            0.0  037_S_4071                   7524.5            4313.9   \n",
       "1            1.0  018_S_4400                   7040.7            2889.0   \n",
       "2            2.0  029_S_4290                   6034.1            3711.6   \n",
       "3            3.0  029_S_4652                   6008.3            2884.1   \n",
       "4            4.0  031_S_4474                   6948.1            3291.7   \n",
       "...          ...         ...                      ...               ...   \n",
       "1201         NaN      992774                   8416.0            3756.0   \n",
       "1202         NaN      993675                   7477.0            3449.0   \n",
       "1203         NaN      994273                   8416.0            4236.0   \n",
       "1204         NaN      995174                   9334.0            4546.0   \n",
       "1205         NaN      996782                   8793.0            4432.0   \n",
       "\n",
       "      FS_L_Putamen_Vol  FS_L_Pallidum_Vol  FS_L_Hippo_Vol  FS_L_Amygdala_Vol  \\\n",
       "0               4709.2             2411.9          4141.2             1453.2   \n",
       "1               4192.5             1805.1          3917.6             1660.1   \n",
       "2               4222.0             2110.8          3113.6             1434.0   \n",
       "3               3715.7             1612.7          3478.3             1190.9   \n",
       "4               3953.5             1728.6          3193.5             1227.4   \n",
       "...                ...                ...             ...                ...   \n",
       "1201            5080.0             1188.0          4250.0             1473.0   \n",
       "1202            4874.0             1054.0          4571.0             1358.0   \n",
       "1203            5961.0             1364.0          4159.0             1627.0   \n",
       "1204            6769.0             1497.0          4616.0             1629.0   \n",
       "1205            6086.0             1364.0          5133.0             1605.0   \n",
       "\n",
       "      FS_L_AccumbensArea_Vol  FS_R_ThalamusProper_Vol  ...  \\\n",
       "0                      303.6                   7778.8  ...   \n",
       "1                      390.7                   6533.8  ...   \n",
       "2                      439.5                   5530.9  ...   \n",
       "3                      457.1                   5293.9  ...   \n",
       "4                      469.7                   6342.0  ...   \n",
       "...                      ...                      ...  ...   \n",
       "1201                   538.0                   6862.0  ...   \n",
       "1202                   564.0                   6879.0  ...   \n",
       "1203                   700.0                   8228.0  ...   \n",
       "1204                   535.0                   8032.0  ...   \n",
       "1205                   726.0                   7665.0  ...   \n",
       "\n",
       "      FS_L_WM_Hypointens_Vol  FS_R_WM_Hypointens_Vol  \\\n",
       "0                        NaN                     NaN   \n",
       "1                        NaN                     NaN   \n",
       "2                        NaN                     NaN   \n",
       "3                        NaN                     NaN   \n",
       "4                        NaN                     NaN   \n",
       "...                      ...                     ...   \n",
       "1201                     0.0                     0.0   \n",
       "1202                     0.0                     0.0   \n",
       "1203                     0.0                     0.0   \n",
       "1204                     0.0                     0.0   \n",
       "1205                     0.0                     0.0   \n",
       "\n",
       "      FS_L_Non-WM_Hypointens_Vol  FS_R_Non-WM_Hypointens_Vol  \\\n",
       "0                            NaN                         NaN   \n",
       "1                            NaN                         NaN   \n",
       "2                            NaN                         NaN   \n",
       "3                            NaN                         NaN   \n",
       "4                            NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "1201                         0.0                         0.0   \n",
       "1202                         0.0                         0.0   \n",
       "1203                         0.0                         0.0   \n",
       "1204                         0.0                         0.0   \n",
       "1205                         0.0                         0.0   \n",
       "\n",
       "      FS_OpticChiasm_Vol  FS_CC_Posterior_Vol  FS_CC_MidPosterior_Vol  \\\n",
       "0                    NaN                  NaN                     NaN   \n",
       "1                    NaN                  NaN                     NaN   \n",
       "2                    NaN                  NaN                     NaN   \n",
       "3                    NaN                  NaN                     NaN   \n",
       "4                    NaN                  NaN                     NaN   \n",
       "...                  ...                  ...                     ...   \n",
       "1201               224.0                971.0                   458.0   \n",
       "1202               107.0                702.0                   269.0   \n",
       "1203               232.0                908.0                   339.0   \n",
       "1204               142.0                765.0                   441.0   \n",
       "1205               172.0                753.0                   495.0   \n",
       "\n",
       "      FS_CC_Central_Vol  FS_CC_MidAnterior_Vol  FS_CC_Anterior_Vol  \n",
       "0                   NaN                    NaN                 NaN  \n",
       "1                   NaN                    NaN                 NaN  \n",
       "2                   NaN                    NaN                 NaN  \n",
       "3                   NaN                    NaN                 NaN  \n",
       "4                   NaN                    NaN                 NaN  \n",
       "...                 ...                    ...                 ...  \n",
       "1201              416.0                  415.0              1004.0  \n",
       "1202              306.0                  319.0               660.0  \n",
       "1203              368.0                  414.0               741.0  \n",
       "1204              458.0                  424.0               863.0  \n",
       "1205              666.0                  511.0               938.0  \n",
       "\n",
       "[1255 rows x 270 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volAndCN_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['FS_L_ThalamusProper_Vol', 'FS_L_Caudate_Vol', 'FS_L_Putamen_Vol', 'FS_L_Pallidum_Vol', \n",
    "            'FS_L_Hippo_Vol', 'FS_L_Amygdala_Vol', 'FS_L_AccumbensArea_Vol', 'FS_R_ThalamusProper_Vol', \n",
    "            'FS_R_Caudate_Vol', 'FS_R_Putamen_Vol', 'FS_R_Pallidum_Vol', 'FS_R_Hippo_Vol', 'FS_R_Amygdala_Vol', \n",
    "            'FS_R_AccumbensArea_Vol', 'FS_L_Bankssts_Thck', 'FS_L_Caudalanteriorcingulate_Thck', \n",
    "            'FS_L_Caudalmiddlefrontal_Thck', 'FS_L_Cuneus_Thck', 'FS_L_Entorhinal_Thck', 'FS_L_Fusiform_Thck', \n",
    "            'FS_L_Inferiorparietal_Thck', 'FS_L_Inferiortemporal_Thck', 'FS_L_Isthmuscingulate_Thck', \n",
    "            'FS_L_Lateraloccipital_Thck', 'FS_L_Lateralorbitofrontal_Thck', 'FS_L_Lingual_Thck', \n",
    "            'FS_L_Medialorbitofrontal_Thck', 'FS_L_Middletemporal_Thck', 'FS_L_Parahippocampal_Thck', \n",
    "            'FS_L_Paracentral_Thck', 'FS_L_Parsopercularis_Thck', 'FS_L_Parsorbitalis_Thck', \n",
    "            'FS_L_Parstriangularis_Thck', 'FS_L_Pericalcarine_Thck', 'FS_L_Postcentral_Thck', \n",
    "            'FS_L_Posteriorcingulate_Thck', 'FS_L_Precentral_Thck', 'FS_L_Precuneus_Thck', \n",
    "            'FS_L_Rostralanteriorcingulate_Thck', 'FS_L_Rostralmiddlefrontal_Thck', 'FS_L_Superiorfrontal_Thck', \n",
    "            'FS_L_Superiorparietal_Thck', 'FS_L_Superiortemporal_Thck', 'FS_L_Supramarginal_Thck', \n",
    "            'FS_L_Frontalpole_Thck', 'FS_L_Temporalpole_Thck', 'FS_L_Transversetemporal_Thck', \n",
    "            'FS_L_Insula_Thck', 'FS_R_Bankssts_Thck', 'FS_R_Caudalanteriorcingulate_Thck', \n",
    "            'FS_R_Caudalmiddlefrontal_Thck', 'FS_R_Cuneus_Thck', 'FS_R_Entorhinal_Thck', 'FS_R_Fusiform_Thck', \n",
    "            'FS_R_Inferiorparietal_Thck', 'FS_R_Inferiortemporal_Thck', 'FS_R_Isthmuscingulate_Thck', \n",
    "            'FS_R_Lateraloccipital_Thck', 'FS_R_Lateralorbitofrontal_Thck', 'FS_R_Lingual_Thck', \n",
    "            'FS_R_Medialorbitofrontal_Thck', 'FS_R_Middletemporal_Thck', 'FS_R_Parahippocampal_Thck', \n",
    "            'FS_R_Paracentral_Thck', 'FS_R_Parsopercularis_Thck', 'FS_R_Parsorbitalis_Thck', \n",
    "            'FS_R_Parstriangularis_Thck', 'FS_R_Pericalcarine_Thck', 'FS_R_Postcentral_Thck', \n",
    "            'FS_R_Posteriorcingulate_Thck', 'FS_R_Precentral_Thck', 'FS_R_Precuneus_Thck', \n",
    "            'FS_R_Rostralanteriorcingulate_Thck', 'FS_R_Rostralmiddlefrontal_Thck', \n",
    "            'FS_R_Superiorfrontal_Thck', 'FS_R_Superiorparietal_Thck', 'FS_R_Superiortemporal_Thck',\n",
    "            'FS_R_Supramarginal_Thck', 'FS_R_Frontalpole_Thck', 'FS_R_Temporalpole_Thck', \n",
    "            'FS_R_Transversetemporal_Thck', 'FS_R_Insula_Thck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert pd.Dataframe to feature(np.array) here ## with label here\n",
    "def Convert2FeatureVectorWithLabel(pdFrame):\n",
    "    subject = []\n",
    "    pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'] = 1.0 / pdFrame['FS_BrainSeg_Vol_No_Vent_Surf']\n",
    "    X = []\n",
    "    x =[]\n",
    "    weighted_mean_feature_dict = {}\n",
    "    for feature in features:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame[feature_area]).sum() / pdFrame[feature_area].sum()\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf']).sum() / pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'].sum()   \n",
    "    variance_feature_dict = {}\n",
    "    for feature in features:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[feature_area] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[feature_area].sum() - (np.square(pdFrame[feature_area])).sum() / pdFrame[feature_area].sum()))\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum() - (np.square(pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"])).sum() / pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum()))\n",
    "    for index,row in pdFrame.iterrows():\n",
    "        for feature in features:\n",
    "            x.append((np.float(row[feature]) - weighted_mean_feature_dict[feature]) / variance_feature_dict[feature])\n",
    "#         x.append(row['Subject'])\n",
    "        subject.append(row['Subject'])\n",
    "        x.append(row['Label'])\n",
    "        X.append(x)\n",
    "        x =[]\n",
    "        if len(X) % 100 == 0:\n",
    "            pass\n",
    "#             print(\"finish 100\")\n",
    "    X = np.array(X)\n",
    "    return X, subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vector_with_Label, Vector_subject = Convert2FeatureVectorWithLabel(all_data)\n",
    "print(Vector_with_Label.shape)\n",
    "\n",
    "print(Vector_with_Label[:,0:-1].shape,Vector_with_Label[:,-1].shape)\n",
    "X = Vector_with_Label[:,0:-1]\n",
    "y = Vector_with_Label[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(12,8,1), random_state=1,max_iter=700)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCI_vector,MCI_subject = Convert2FeatureVector(MCI_freesurfer_Out)\n",
    "volner_vector, volner_subject = Convert2FeatureVector(volner)\n",
    "\n",
    "MCI_label = np.ones(302)\n",
    "volner_label = np.zeros(1113)\n",
    "print(MCI_label.shape,volner_label.shape)\n",
    "y = np.concatenate((MCI_label,volner_label))\n",
    "print(y.shape)\n",
    "\n",
    "X = np.concatenate((MCI_vector,volner_vector))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(64,128), random_state=1,max_iter=700)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Vector_with_Label, Vector_subject = Convert2FeatureVectorWithLabel(all_data)\n",
    "print(Vector_with_Label.shape)\n",
    "print(Vector_with_Label[:,0:-1].shape,Vector_with_Label[:,-1].shape)\n",
    "X = Vector_with_Label[:,0:-1]\n",
    "y = Vector_with_Label[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=82, activation='relu'))\n",
    "model.add(Dense(6, activation='relu',name = 'my_layer'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterFeatureExtractor(data_with_volner,data_without_volner):\n",
    "    Vector_with_Label, Vector_subject = Convert2FeatureVectorWithLabel(data_with_volner)\n",
    "    Vector_without_volner_with_Label, Vector_without_volner_Vector_subject = Convert2FeatureVectorWithLabel(data_without_volner)\n",
    "    print(Vector_with_Label.shape)\n",
    "    print(Vector_with_Label[:,0:-1].shape,Vector_with_Label[:,-1].shape)\n",
    "    X = Vector_with_Label[:,0:-1]\n",
    "    y = Vector_with_Label[:,-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=82, activation='relu'))\n",
    "    model.add(Dense(6, activation='relu',name = 'my_layer'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train, y_train, epochs=15, batch_size=10)\n",
    "    # evaluate the keras model\n",
    "    _, accuracy = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy: %.2f' % (accuracy*100))\n",
    "    layer_name = 'my_layer'\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    intermediate_output = intermediate_layer_model.predict(Vector_without_volner_with_Label[:,0:-1])\n",
    "    print(intermediate_output.shape)\n",
    "    return intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "(1255, 83)\n",
      "(1255, 82) (1255,)\n",
      "Epoch 1/15\n",
      "878/878 [==============================] - 0s 312us/step - loss: 0.7669 - accuracy: 0.4806\n",
      "Epoch 2/15\n",
      "878/878 [==============================] - 0s 131us/step - loss: 0.3288 - accuracy: 0.9339\n",
      "Epoch 3/15\n",
      "878/878 [==============================] - 0s 137us/step - loss: 0.1581 - accuracy: 0.9841\n",
      "Epoch 4/15\n",
      "878/878 [==============================] - 0s 129us/step - loss: 0.0948 - accuracy: 0.9886\n",
      "Epoch 5/15\n",
      "878/878 [==============================] - 0s 134us/step - loss: 0.0600 - accuracy: 0.9966\n",
      "Epoch 6/15\n",
      "878/878 [==============================] - 0s 130us/step - loss: 0.0403 - accuracy: 0.9977\n",
      "Epoch 7/15\n",
      "878/878 [==============================] - 0s 139us/step - loss: 0.0286 - accuracy: 0.9989\n",
      "Epoch 8/15\n",
      "878/878 [==============================] - 0s 133us/step - loss: 0.0203 - accuracy: 0.9989\n",
      "Epoch 9/15\n",
      "878/878 [==============================] - 0s 139us/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "878/878 [==============================] - 0s 132us/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "878/878 [==============================] - 0s 132us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "878/878 [==============================] - 0s 134us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "878/878 [==============================] - 0s 135us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "878/878 [==============================] - 0s 132us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "878/878 [==============================] - 0s 134us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "377/377 [==============================] - 0s 86us/step\n",
      "Accuracy: 99.73\n",
      "(142, 6)\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "(1694, 83)\n",
      "(1694, 82) (1694,)\n",
      "Epoch 1/15\n",
      "1185/1185 [==============================] - 0s 266us/step - loss: 0.1864 - accuracy: 0.9544\n",
      "Epoch 2/15\n",
      "1185/1185 [==============================] - 0s 137us/step - loss: 0.0583 - accuracy: 0.9941\n",
      "Epoch 3/15\n",
      "1185/1185 [==============================] - 0s 135us/step - loss: 0.0289 - accuracy: 0.9958\n",
      "Epoch 4/15\n",
      "1185/1185 [==============================] - 0s 135us/step - loss: 0.0163 - accuracy: 0.9975\n",
      "Epoch 5/15\n",
      "1185/1185 [==============================] - 0s 134us/step - loss: 0.0102 - accuracy: 0.9992\n",
      "Epoch 6/15\n",
      "1185/1185 [==============================] - 0s 134us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "1185/1185 [==============================] - 0s 139us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "1185/1185 [==============================] - 0s 133us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "1185/1185 [==============================] - 0s 134us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "1185/1185 [==============================] - 0s 134us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "1185/1185 [==============================] - 0s 137us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "1185/1185 [==============================] - 0s 135us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "1185/1185 [==============================] - 0s 135us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "1185/1185 [==============================] - 0s 141us/step - loss: 9.8825e-04 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "1185/1185 [==============================] - 0s 139us/step - loss: 8.1658e-04 - accuracy: 1.0000\n",
      "509/509 [==============================] - 0s 70us/step\n",
      "Accuracy: 99.80\n",
      "(581, 6)\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "(1299, 83)\n",
      "(1299, 82) (1299,)\n",
      "Epoch 1/15\n",
      "909/909 [==============================] - 0s 287us/step - loss: 0.3458 - accuracy: 0.9230\n",
      "Epoch 2/15\n",
      "909/909 [==============================] - 0s 138us/step - loss: 0.1568 - accuracy: 0.9538\n",
      "Epoch 3/15\n",
      "909/909 [==============================] - 0s 136us/step - loss: 0.0817 - accuracy: 0.9813\n",
      "Epoch 4/15\n",
      "909/909 [==============================] - 0s 137us/step - loss: 0.0427 - accuracy: 0.9934\n",
      "Epoch 5/15\n",
      "909/909 [==============================] - 0s 138us/step - loss: 0.0232 - accuracy: 0.9967\n",
      "Epoch 6/15\n",
      "909/909 [==============================] - 0s 134us/step - loss: 0.0143 - accuracy: 0.9989\n",
      "Epoch 7/15\n",
      "909/909 [==============================] - 0s 138us/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "909/909 [==============================] - 0s 136us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "909/909 [==============================] - 0s 139us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "909/909 [==============================] - 0s 134us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "909/909 [==============================] - 0s 131us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "909/909 [==============================] - 0s 133us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "909/909 [==============================] - 0s 136us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "909/909 [==============================] - 0s 138us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "909/909 [==============================] - 0s 135us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "390/390 [==============================] - 0s 84us/step\n",
      "Accuracy: 100.00\n",
      "(186, 6)\n"
     ]
    }
   ],
   "source": [
    "CN_intermediate_output = clusterFeatureExtractor(volAndCN_data,CN_freesurfer_Out)\n",
    "MCI_intermediate_output = clusterFeatureExtractor(volAndMCI_data,MCI_freesurfer_Out)\n",
    "AD_intermediate_output = clusterFeatureExtractor(volAndAD_data,AD_freesurfer_Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build my input for clustering\n",
    "layer_name = 'my_layer'\n",
    "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(MCI_vector)\n",
    "print(intermediate_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterInput = MCI_intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusterInput[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means methods"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    ">>> from sklearn.cluster import KMeans\n",
    ">>> import numpy as np\n",
    ">>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "...               [10, 2], [10, 4], [10, 0]])\n",
    ">>> kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    ">>> kmeans.labels_\n",
    "array([1, 1, 1, 0, 0, 0], dtype=int32)\n",
    ">>> kmeans.predict([[0, 0], [12, 3]])\n",
    "array([1, 0], dtype=int32)\n",
    ">>> kmeans.cluster_centers_\n",
    "array([[10.,  2.],\n",
    "       [ 1.,  2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(clusterInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 0, 1, 2, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1,\n",
       "       0, 2, 0, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 0, 2, 1, 0,\n",
       "       1, 0, 2, 0, 0, 2, 2, 1, 0, 1, 2, 1, 1, 0, 2, 0, 0, 1, 1, 1, 1, 2,\n",
       "       1, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 0, 1, 2, 0, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 1, 2, 1, 1, 1, 1, 0, 2, 0,\n",
       "       1, 1, 2, 1, 1, 1, 0, 2, 1, 0, 2, 2, 1, 2, 0, 0, 1, 0, 0, 1, 0, 2,\n",
       "       0, 1, 1, 2, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 0, 1, 2, 2, 2, 1, 0, 0, 1,\n",
       "       0, 1, 2, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 0,\n",
       "       0, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 0, 0, 2,\n",
       "       1, 2, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 2, 1, 1, 1,\n",
       "       1, 1, 0, 2, 1, 2, 1, 0, 2, 0, 1, 1, 1, 2, 1, 0, 2, 1, 1, 2, 2, 2,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 0, 1, 0, 2, 0, 2, 1, 1, 0, 1, 2, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 0, 0, 0, 2, 1, 0, 1, 1, 1, 2, 1,\n",
       "       0, 1, 2, 2, 1, 1, 2, 1, 1, 0, 2, 1, 2, 2, 2, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       2, 2, 1, 1, 1, 0, 2, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       2, 0, 2, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 2, 0, 1, 2, 1, 1, 0, 1, 2, 2, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 0, 0, 2, 1, 1, 1, 2,\n",
       "       1, 2, 2, 2, 0, 0, 1, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the start of draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(csvPath,\"MCI_sne.tsv\"),MCI_vector,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(csvPath,\"all_data.tsv\"),Vector_with_Label[:,0:-1],delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt(os.path.join(csvPath,'pima-indians-diabetes.data.csv'), delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt(os.path.join(csvPath,'pima-indians-diabetes.data.csv'), delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=15, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the start of draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert pd.Dataframe to feature(np.array) here ## No label here\n",
    "def Convert2FeatureVector(pdFrame):\n",
    "    subject = []\n",
    "    pdFrame = pdFrame.dropna()\n",
    "    pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'] = 1.0 / pdFrame['FS_BrainSeg_Vol_No_Vent_Surf']\n",
    "    X = []\n",
    "    x =[]\n",
    "    weighted_mean_feature_dict = {}\n",
    "    for feature in features:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame[feature_area]).sum() / pdFrame[feature_area].sum()\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf']).sum() / pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'].sum()   \n",
    "    variance_feature_dict = {}\n",
    "    for feature in features:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[feature_area] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[feature_area].sum() - (np.square(pdFrame[feature_area])).sum() / pdFrame[feature_area].sum()))\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum() - (np.square(pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"])).sum() / pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum()))\n",
    "    for index,row in pdFrame.iterrows():\n",
    "        for feature in features:\n",
    "            x.append((np.float(row[feature]) - weighted_mean_feature_dict[feature]) / variance_feature_dict[feature])\n",
    "#         x.append(row['Subject'])\n",
    "        X.append(x)\n",
    "        subject.append(row['Subject'])\n",
    "        x =[]\n",
    "        if len(X) % 100 == 0:\n",
    "            print(\"finish 100\")\n",
    "    X = np.array(X)\n",
    "    return X, subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(64,100), random_state=1,max_iter=700).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volner_no_Nan = volner.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weighted_mean_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mean_feature_dict = {}\n",
    "for feature in features:\n",
    "    if feature.split('_')[-1] == 'Thck':\n",
    "        feature_area = feature[0:-4] + 'Area'\n",
    "        weighted_mean_feature_dict[feature] = (volner_no_Nan[feature] * volner_no_Nan[feature_area]).sum() / volner_no_Nan[feature_area].sum()\n",
    "    if feature.split('_')[-1] == 'Vol':\n",
    "        weighted_mean_feature_dict[feature] = (volner_no_Nan[feature] * volner_no_Nan['reverse_FS_BrainSeg_Vol_No_Vent_Surf']).sum() / volner_no_Nan['reverse_FS_BrainSeg_Vol_No_Vent_Surf'].sum()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_feature_dict = {}\n",
    "for feature in features:\n",
    "    if feature.split('_')[-1] == 'Thck':\n",
    "        feature_area = feature[0:-4] + 'Area'\n",
    "        variance_feature_dict[feature] = np.sqrt((volner_no_Nan[feature_area] * np.square(volner_no_Nan[feature] - weighted_mean_feature_dict[feature])).sum() / (volner_no_Nan[feature_area].sum() - (np.square(volner_no_Nan[feature_area])).sum() / volner_no_Nan[feature_area].sum()))\n",
    "    if feature.split('_')[-1] == 'Vol':\n",
    "        variance_feature_dict[feature] = np.sqrt((volner_no_Nan[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"] * np.square(volner_no_Nan[feature] - weighted_mean_feature_dict[feature])).sum() / (volner_no_Nan[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum() - (np.square(volner_no_Nan[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"])).sum() / volner_no_Nan[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volner_no_Nan['reverse_FS_BrainSeg_Vol_No_Vent_Surf'] = 1.0 / volner_no_Nan['FS_BrainSeg_Vol_No_Vent_Surf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variance_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "x =[]\n",
    "for index,row in volner_no_Nan.iterrows():\n",
    "    for feature in features:\n",
    "        x.append((np.float(row[feature]) - weighted_mean_feature_dict[feature]) / variance_feature_dict[feature])\n",
    "    X.append(x)\n",
    "    x =[]\n",
    "    if len(X) % 100 == 0:\n",
    "        print(\"finish 100\")\n",
    "X = np.array(X)      \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectFeatures2 = [\"left-wthi-bankssts\",\"left-wthi-caudalanteriorcingulate\",\"left-wthi-caudalmiddlefrontal\",\n",
    "                  \"left-wthi-cuneus\",\"left-wthi-entorhinal\",\"left-wthi-fusiform\",\"left-wthi-inferiorparietal\",\n",
    "                  \"left-wthi-inferiortemporal\",\"left-wthi-isthmuscingulate\",\"left-wthi-lateraloccipital\",\n",
    "                  \"left-wthi-lateralorbitofrontal\",\"left-wthi-lingual\",\"left-wthi-medialorbitofrontal\",\n",
    "                  \"left-wthi-middletemporal\",\"left-wthi-parahippocampal\",\"left-wthi-paracentral\",\n",
    "                  \"left-wthi-parsopercularis\",\"left-wthi-parsorbitalis\",\"left-wthi-parstriangularis\",\n",
    "                  \"left-wthi-pericalcarine\",\"left-wthi-postcentral\",\"left-wthi-posteriorcingulate\",\n",
    "                  \"left-wthi-precentral\",\"left-wthi-precuneus\",\"left-wthi-rostralanteriorcingulate\",\n",
    "                  \"left-wthi-rostralmiddlefrontal\",\"left-wthi-superiorfrontal\",\"left-wthi-superiorparietal\",\n",
    "                  \"left-wthi-superiortemporal\",\"left-wthi-supramarginal\",\"left-wthi-frontalpole\",\n",
    "                  \"left-wthi-temporalpole\",\"left-wthi-transversetemporal\",\"left-wthi-insula\",\"right-wthi-bankssts\",\n",
    "                  \"right-wthi-caudalanteriorcingulate\",\"right-wthi-caudalmiddlefrontal\",\"right-wthi-cuneus\",\n",
    "                  \"right-wthi-entorhinal\",\"right-wthi-fusiform\",\"right-wthi-inferiorparietal\",\n",
    "                  \"right-wthi-inferiortemporal\",\"right-wthi-isthmuscingulate\",\"right-wthi-lateraloccipital\",\n",
    "                  \"right-wthi-lateralorbitofrontal\",\"right-wthi-lingual\",\"right-wthi-medialorbitofrontal\",\n",
    "                  \"right-wthi-middletemporal\",\"right-wthi-parahippocampal\",\"right-wthi-paracentral\",\n",
    "                  \"right-wthi-parsopercularis\",\"right-wthi-parsorbitalis\",\"right-wthi-parstriangularis\",\n",
    "                  \"right-wthi-pericalcarine\",\"right-wthi-postcentral\",\"right-wthi-posteriorcingulate\",\n",
    "                  \"right-wthi-precentral\",\"right-wthi-precuneus\",\"right-wthi-rostralanteriorcingulate\",\n",
    "                  \"right-wthi-rostralmiddlefrontal\",\"right-wthi-superiorfrontal\",\"right-wthi-superiorparietal\",\n",
    "                  \"right-wthi-superiortemporal\",\"right-wthi-supramarginal\",\"right-wthi-frontalpole\",\n",
    "                  \"right-wthi-temporalpole\",\"right-wthi-transversetemporal\",\"right-wthi-insula\",\n",
    "                  \"right-svol-Thalamus\",\"right-svol-Caudate\",\"right-svol-Putamen\",\"right-svol-Pallidum\",\n",
    "                  \"right-svol-Hippocampus\",\"right-svol-Amygdala\",\"right-svol-Accumbens\",\"left-svol-Thalamus\",\n",
    "                  \"left-svol-Caudate\",\"left-svol-Putamen\",\"left-svol-Pallidum\",\"left-svol-Hippocampus\",\n",
    "                  \"left-svol-Amygdala\",\"left-svol-Accumbens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the jwt token (run bl login to create this file)\n",
    "jwt_file = open(os.environ['HOME']+'/.config/brainlife.io/.jwt', mode='r')\n",
    "jwt = jwt_file.read()\n",
    "#query datasets records\n",
    "find = { \n",
    "    '_group_id': '69', #see project detail page \n",
    "    'service': 'brainlife/app-freesurfer', \n",
    "    #'service_branch': '0.0.5',\n",
    "    'status': 'finished' }\n",
    "params = { \n",
    "    'limit': 100, \n",
    "    'select': 'config._inputs.meta', #we just want product and meta\n",
    "    'find': json.JSONEncoder().encode(find) }\n",
    "res = requests.get('https://brainlife.io/api/amaretti/task', params=params, headers={'Authorization': 'Bearer '+jwt})\n",
    "if res.status_code != 200:\n",
    "    raise Exception(\"failed to download datasets list:\"+res.status_code)\n",
    "tasks = res.json()[\"tasks\"]\n",
    "for task in tasks:\n",
    "    taskid=task[\"_id\"]\n",
    "    subject=task[\"config\"][\"_inputs\"][0][\"meta\"][\"subject\"]\n",
    "    print(taskid, subject)\n",
    "    url = 'https://brainlife.io/api/amaretti/task/download/'+taskid+'/freesurfer/output/stats?at='+jwt\n",
    "    res = requests.get(url, allow_redirects=True)\n",
    "    open(subject+'.tar.gz', 'wb').write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://brainlife.io/api/amaretti/resource',headers={'Authorization': 'Bearer '+jwt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This verison is for all volume feature\n",
    "selectFeatures1 = [\"left-vol-bankssts\",\"left-vol-caudalanteriorcingulate\",\"left-vol-caudalmiddlefrontal\",\n",
    "                  \"left-vol-cuneus\",\"left-vol-entorhinal\",\"left-vol-fusiform\",\"left-vol-inferiorparietal\",\n",
    "                  \"left-vol-inferiortemporal\",\"left-vol-isthmuscingulate\",\"left-vol-lateraloccipital\",\n",
    "                  \"left-vol-lateralorbitofrontal\",\"left-vol-lingual\",\"left-vol-medialorbitofrontal\",\n",
    "                  \"left-vol-middletemporal\",\"left-vol-parahippocampal\",\"left-vol-paracentral\",\n",
    "                  \"left-vol-parsopercularis\",\"left-vol-parsorbitalis\",\"left-vol-parstriangularis\",\n",
    "                  \"left-vol-pericalcarine\",\"left-vol-postcentral\",\"left-vol-posteriorcingulate\",\n",
    "                  \"left-vol-precentral\",\"left-vol-precuneus\",\"left-vol-rostralanteriorcingulate\",\n",
    "                  \"left-vol-rostralmiddlefrontal\",\"left-vol-superiorfrontal\",\"left-vol-superiorparietal\",\n",
    "                  \"left-vol-superiortemporal\",\"left-vol-supramarginal\",\"left-vol-frontalpole\",\n",
    "                  \"left-vol-temporalpole\",\"left-vol-transversetemporal\",\"left-vol-insula\",\"right-vol-bankssts\",\n",
    "                  \"right-vol-caudalanteriorcingulate\",\"right-vol-caudalmiddlefrontal\",\"right-vol-cuneus\",\n",
    "                  \"right-vol-entorhinal\",\"right-vol-fusiform\",\"right-vol-inferiorparietal\",\n",
    "                  \"right-vol-inferiortemporal\",\"right-vol-isthmuscingulate\",\"right-vol-lateraloccipital\",\n",
    "                  \"right-vol-lateralorbitofrontal\",\"right-vol-lingual\",\"right-vol-medialorbitofrontal\",\n",
    "                  \"right-vol-middletemporal\",\"right-vol-parahippocampal\",\"right-vol-paracentral\",\n",
    "                  \"right-vol-parsopercularis\",\"right-vol-parsorbitalis\",\"right-vol-parstriangularis\",\n",
    "                  \"right-vol-pericalcarine\",\"right-vol-postcentral\",\"right-vol-posteriorcingulate\",\n",
    "                  \"right-vol-precentral\",\"right-vol-precuneus\",\"right-vol-rostralanteriorcingulate\",\n",
    "                  \"right-vol-rostralmiddlefrontal\",\"right-vol-superiorfrontal\",\"right-vol-superiorparietal\",\n",
    "                  \"right-vol-superiortemporal\",\"right-vol-supramarginal\",\"right-vol-frontalpole\",\n",
    "                  \"right-vol-temporalpole\",\"right-vol-transversetemporal\",\"right-vol-insula\",\n",
    "                  \"right-svol-Thalamus\",\"right-svol-Caudate\",\"right-svol-Putamen\",\"right-svol-Pallidum\",\n",
    "                  \"right-svol-Hippocampus\",\"right-svol-Amygdala\",\"right-svol-Accumbens\",\"left-svol-Thalamus\",\n",
    "                  \"left-svol-Caudate\",\"left-svol-Putamen\",\"left-svol-Pallidum\",\"left-svol-Hippocampus\",\n",
    "                  \"left-svol-Amygdala\",\"left-svol-Accumbens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(type(x))\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volner_tensor = torch.tensor(volner_vector)\n",
    "volner_tensor2 = torch.from_numpy(volner_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
