{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "import torch\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense\n",
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型想法：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ./csvFiles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvPath = \"/home/ubuntu/Desktop/ADNI_MRI_Image/neuroScript/csvFiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "volner = pd.read_csv(os.path.join(csvPath,\"Freesurfer_S1200_Extensively_Processed_fMRI_Data.csv\"))\n",
    "volner = volner.dropna()\n",
    "# MCI_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"MCI_amyloid_pos_freeStatsOut.csv\"))\n",
    "MCI_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"MCI_all_freeStatsOut.csv\"))\n",
    "MCI_freesurfer_Out = MCI_freesurfer_Out.dropna()\n",
    "AD_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"AD_all_freeStatsOut.csv\"))\n",
    "AD_freesurfer_Out = AD_freesurfer_Out.dropna()\n",
    "CN_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"CN_all_freeStatsOut.csv\"))\n",
    "CN_freesurfer_Out = CN_freesurfer_Out.dropna()\n",
    "volner['Label'] = 0\n",
    "AD_freesurfer_Out['Label'] = 1\n",
    "MCI_freesurfer_Out['Label'] = 1\n",
    "CN_freesurfer_Out['Label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/spm/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (19,20,21,104,105) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ubuntu/anaconda3/envs/spm/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/ubuntu/anaconda3/envs/spm/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/home/ubuntu/anaconda3/envs/spm/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ubuntu/anaconda3/envs/spm/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#此处的萎缩模型：此处认为amyloid以及tau均为阳性的为阳性，其余均为阴性\n",
    "MCI_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"MCI_all_freeStatsOut.csv\"))\n",
    "MCI_freesurfer_Out = MCI_freesurfer_Out.dropna()\n",
    "MCI_Within1Year = list(pd.read_csv(os.path.join(csvPath,\"MCIWithin1Year.csv\"))['PTID'])\n",
    "MCI_freesurfer_Out_within1Year = MCI_freesurfer_Out[MCI_freesurfer_Out['Subject'].isin(MCI_Within1Year)]\n",
    "ADNIMERGE_withTau_AbetaTauPosNeg = pd.read_csv(os.path.join(csvPath,'ADNIMERGE_withTau_AbetaTauPosNeg.csv'))\n",
    "MCI_amyloid_tau_pos_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[ADNIMERGE_withTau_AbetaTauPosNeg['AbetaTauPosOrNeg'] == 1.0]['PTID'])\n",
    "\n",
    "MCI_freesurfer_Out_within1Year['Label'] = 0\n",
    "MCI_freesurfer_Out_within1Year.loc[MCI_freesurfer_Out_within1Year['Subject'].isin(MCI_amyloid_tau_pos_list),'Label'] = 1\n",
    "################################################################################################################################\n",
    "CN_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"CN_all_freeStatsOut.csv\"))\n",
    "CN_freesurfer_Out = CN_freesurfer_Out.dropna()\n",
    "CN_Within1Year = list(pd.read_csv(os.path.join(csvPath,\"CNWithin1Year.csv\"))['PTID'])\n",
    "CN_freesurfer_Out_within1Year = CN_freesurfer_Out[CN_freesurfer_Out['Subject'].isin(CN_Within1Year)]\n",
    "ADNIMERGE_withTau_AbetaTauPosNeg = pd.read_csv(os.path.join(csvPath,'ADNIMERGE_withTau_AbetaTauPosNeg.csv'))\n",
    "CN_amyloid_tau_pos_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[ADNIMERGE_withTau_AbetaTauPosNeg['AbetaTauPosOrNeg'] == 1.0]['PTID'])\n",
    "\n",
    "CN_freesurfer_Out_within1Year['Label'] = 0\n",
    "CN_freesurfer_Out_within1Year.loc[CN_freesurfer_Out_within1Year['Subject'].isin(CN_amyloid_tau_pos_list),'Label'] = 1\n",
    "################################################################################################################################\n",
    "AD_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"AD_all_freeStatsOut.csv\"))\n",
    "AD_freesurfer_Out = AD_freesurfer_Out.dropna()\n",
    "AD_Within1Year = list(pd.read_csv(os.path.join(csvPath,\"ADWithin1Year.csv\"))['PTID'])\n",
    "AD_freesurfer_Out_within1Year = AD_freesurfer_Out[AD_freesurfer_Out['Subject'].isin(AD_Within1Year)]\n",
    "ADNIMERGE_withTau_AbetaTauPosNeg = pd.read_csv(os.path.join(csvPath,'ADNIMERGE_withTau_AbetaTauPosNeg.csv'))\n",
    "AD_amyloid_tau_pos_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[ADNIMERGE_withTau_AbetaTauPosNeg['AbetaTauPosOrNeg'] == 1.0]['PTID'])\n",
    "\n",
    "AD_freesurfer_Out_within1Year['Label'] = 0\n",
    "AD_freesurfer_Out_within1Year.loc[AD_freesurfer_Out_within1Year['Subject'].isin(AD_amyloid_tau_pos_list),'Label'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/spm/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ubuntu/anaconda3/envs/spm/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#此处的萎缩模型：此处认为amyloid以及tau均为阳性的为阳性，amyloid阴性(不论tau是否为阴性)的为阴性\n",
    "MCI_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"MCI_all_freeStatsOut.csv\"))\n",
    "MCI_freesurfer_Out = MCI_freesurfer_Out.dropna()\n",
    "MCI_Within1Year = list(pd.read_csv(os.path.join(csvPath,\"MCIWithin1Year.csv\"))['PTID'])\n",
    "MCI_freesurfer_Out_within1Year = MCI_freesurfer_Out[MCI_freesurfer_Out['Subject'].isin(MCI_Within1Year)]\n",
    "ADNIMERGE_withTau_AbetaTauPosNeg = pd.read_csv(os.path.join(csvPath,'ADNIMERGE_withTau_AbetaTauPosNeg.csv'))\n",
    "MCI_amyloid_tau_pos_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[ADNIMERGE_withTau_AbetaTauPosNeg['AbetaTauPosOrNeg'] == 1.0]['PTID'])\n",
    "MCI_amyloid_neg_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[(ADNIMERGE_withTau_AbetaTauPosNeg['AbetaPosOrNeg'] == 0.0) & (ADNIMERGE_withTau_AbetaTauPosNeg['VISCODE'] == 'bl')]['PTID'])\n",
    "\n",
    "MCI_freesurfer_Out_within1Year['Label'] = 2\n",
    "MCI_freesurfer_Out_within1Year.loc[MCI_freesurfer_Out_within1Year['Subject'].isin(MCI_amyloid_tau_pos_list),'Label'] = 1\n",
    "MCI_freesurfer_Out_within1Year.loc[MCI_freesurfer_Out_within1Year['Subject'].isin(MCI_amyloid_neg_list),'Label'] = 0\n",
    "MCI_freesurfer_Out_within1Year = MCI_freesurfer_Out_within1Year[MCI_freesurfer_Out_within1Year['Label'] != 2]\n",
    "#####################################################################################################################\n",
    "AD_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"AD_all_freeStatsOut.csv\"))\n",
    "AD_freesurfer_Out = AD_freesurfer_Out.dropna()\n",
    "AD_Within1Year = list(pd.read_csv(os.path.join(csvPath,\"ADWithin1Year.csv\"))['PTID'])\n",
    "AD_freesurfer_Out_within1Year = AD_freesurfer_Out[AD_freesurfer_Out['Subject'].isin(AD_Within1Year)]\n",
    "ADNIMERGE_withTau_AbetaTauPosNeg = pd.read_csv(os.path.join(csvPath,'ADNIMERGE_withTau_AbetaTauPosNeg.csv'))\n",
    "AD_amyloid_tau_pos_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[ADNIMERGE_withTau_AbetaTauPosNeg['AbetaTauPosOrNeg'] == 1.0]['PTID'])\n",
    "AD_amyloid_neg_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[(ADNIMERGE_withTau_AbetaTauPosNeg['AbetaPosOrNeg'] == 0.0) & (ADNIMERGE_withTau_AbetaTauPosNeg['VISCODE'] == 'bl')]['PTID'])\n",
    "\n",
    "AD_freesurfer_Out_within1Year['Label'] = 2\n",
    "AD_freesurfer_Out_within1Year.loc[AD_freesurfer_Out_within1Year['Subject'].isin(AD_amyloid_tau_pos_list),'Label'] = 1\n",
    "AD_freesurfer_Out_within1Year.loc[AD_freesurfer_Out_within1Year['Subject'].isin(AD_amyloid_neg_list),'Label'] = 0\n",
    "AD_freesurfer_Out_within1Year = AD_freesurfer_Out_within1Year[AD_freesurfer_Out_within1Year['Label'] != 2]\n",
    "#####################################################################################################################\n",
    "CN_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"CN_all_freeStatsOut.csv\"))\n",
    "CN_freesurfer_Out = CN_freesurfer_Out.dropna()\n",
    "CN_Within1Year = list(pd.read_csv(os.path.join(csvPath,\"MCIWithin1Year.csv\"))['PTID'])\n",
    "CN_freesurfer_Out_within1Year = CN_freesurfer_Out[CN_freesurfer_Out['Subject'].isin(CN_Within1Year)]\n",
    "ADNIMERGE_withTau_AbetaTauPosNeg = pd.read_csv(os.path.join(csvPath,'ADNIMERGE_withTau_AbetaTauPosNeg.csv'))\n",
    "CN_amyloid_tau_pos_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[ADNIMERGE_withTau_AbetaTauPosNeg['AbetaTauPosOrNeg'] == 1.0]['PTID'])\n",
    "CN_amyloid_neg_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[(ADNIMERGE_withTau_AbetaTauPosNeg['AbetaPosOrNeg'] == 0.0) & (ADNIMERGE_withTau_AbetaTauPosNeg['VISCODE'] == 'bl')]['PTID'])\n",
    "\n",
    "CN_freesurfer_Out_within1Year['Label'] = 2\n",
    "CN_freesurfer_Out_within1Year.loc[CN_freesurfer_Out_within1Year['Subject'].isin(CN_amyloid_tau_pos_list),'Label'] = 1\n",
    "CN_freesurfer_Out_within1Year.loc[CN_freesurfer_Out_within1Year['Subject'].isin(CN_amyloid_neg_list),'Label'] = 0\n",
    "CN_freesurfer_Out_within1Year = CN_freesurfer_Out_within1Year[CN_freesurfer_Out_within1Year['Label'] != 2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/spm/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ubuntu/anaconda3/envs/spm/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#此处的萎缩模型：此处认为amyloid为阳性的则为阳性，amyloid阴性(不论tau是否为阴性)的为阴性\n",
    "MCI_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"MCI_all_freeStatsOut.csv\"))\n",
    "MCI_freesurfer_Out = MCI_freesurfer_Out.dropna()\n",
    "MCI_Within1Year = list(pd.read_csv(os.path.join(csvPath,\"MCIWithin1Year.csv\"))['PTID'])\n",
    "MCI_freesurfer_Out_within1Year = MCI_freesurfer_Out[MCI_freesurfer_Out['Subject'].isin(MCI_Within1Year)]\n",
    "ADNIMERGE_withTau_AbetaTauPosNeg = pd.read_csv(os.path.join(csvPath,'ADNIMERGE_withTau_AbetaTauPosNeg.csv'))\n",
    "MCI_amyloid_pos_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[ADNIMERGE_withTau_AbetaTauPosNeg['AbetaPosOrNeg'] == 1.0]['PTID'])\n",
    "MCI_amyloid_neg_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[(ADNIMERGE_withTau_AbetaTauPosNeg['AbetaPosOrNeg'] == 0.0) & (ADNIMERGE_withTau_AbetaTauPosNeg['VISCODE'] == 'bl')]['PTID'])\n",
    "\n",
    "MCI_freesurfer_Out_within1Year['Label'] = 2\n",
    "MCI_freesurfer_Out_within1Year.loc[MCI_freesurfer_Out_within1Year['Subject'].isin(MCI_amyloid_pos_list),'Label'] = 1\n",
    "MCI_freesurfer_Out_within1Year.loc[MCI_freesurfer_Out_within1Year['Subject'].isin(MCI_amyloid_neg_list),'Label'] = 0\n",
    "MCI_freesurfer_Out_within1Year = MCI_freesurfer_Out_within1Year[MCI_freesurfer_Out_within1Year['Label'] != 2]\n",
    "#####################################################################################################################\n",
    "AD_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"AD_all_freeStatsOut.csv\"))\n",
    "AD_freesurfer_Out = AD_freesurfer_Out.dropna()\n",
    "AD_Within1Year = list(pd.read_csv(os.path.join(csvPath,\"ADWithin1Year.csv\"))['PTID'])\n",
    "AD_freesurfer_Out_within1Year = AD_freesurfer_Out[AD_freesurfer_Out['Subject'].isin(AD_Within1Year)]\n",
    "ADNIMERGE_withTau_AbetaTauPosNeg = pd.read_csv(os.path.join(csvPath,'ADNIMERGE_withTau_AbetaTauPosNeg.csv'))\n",
    "AD_amyloid_pos_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[ADNIMERGE_withTau_AbetaTauPosNeg['AbetaPosOrNeg'] == 1.0]['PTID'])\n",
    "AD_amyloid_neg_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[(ADNIMERGE_withTau_AbetaTauPosNeg['AbetaPosOrNeg'] == 0.0) & (ADNIMERGE_withTau_AbetaTauPosNeg['VISCODE'] == 'bl')]['PTID'])\n",
    "\n",
    "AD_freesurfer_Out_within1Year['Label'] = 2\n",
    "AD_freesurfer_Out_within1Year.loc[AD_freesurfer_Out_within1Year['Subject'].isin(AD_amyloid_pos_list),'Label'] = 1\n",
    "AD_freesurfer_Out_within1Year.loc[AD_freesurfer_Out_within1Year['Subject'].isin(AD_amyloid_neg_list),'Label'] = 0\n",
    "AD_freesurfer_Out_within1Year = AD_freesurfer_Out_within1Year[AD_freesurfer_Out_within1Year['Label'] != 2]\n",
    "#####################################################################################################################\n",
    "CN_freesurfer_Out = pd.read_csv(os.path.join(csvPath,\"CN_all_freeStatsOut.csv\"))\n",
    "CN_freesurfer_Out = CN_freesurfer_Out.dropna()\n",
    "CN_Within1Year = list(pd.read_csv(os.path.join(csvPath,\"MCIWithin1Year.csv\"))['PTID'])\n",
    "CN_freesurfer_Out_within1Year = CN_freesurfer_Out[CN_freesurfer_Out['Subject'].isin(CN_Within1Year)]\n",
    "ADNIMERGE_withTau_AbetaTauPosNeg = pd.read_csv(os.path.join(csvPath,'ADNIMERGE_withTau_AbetaTauPosNeg.csv'))\n",
    "CN_amyloid_pos_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[ADNIMERGE_withTau_AbetaTauPosNeg['AbetaPosOrNeg'] == 1.0]['PTID'])\n",
    "CN_amyloid_neg_list = list(ADNIMERGE_withTau_AbetaTauPosNeg[(ADNIMERGE_withTau_AbetaTauPosNeg['AbetaPosOrNeg'] == 0.0) & (ADNIMERGE_withTau_AbetaTauPosNeg['VISCODE'] == 'bl')]['PTID'])\n",
    "\n",
    "CN_freesurfer_Out_within1Year['Label'] = 2\n",
    "CN_freesurfer_Out_within1Year.loc[CN_freesurfer_Out_within1Year['Subject'].isin(CN_amyloid_pos_list),'Label'] = 1\n",
    "CN_freesurfer_Out_within1Year.loc[CN_freesurfer_Out_within1Year['Subject'].isin(CN_amyloid_neg_list),'Label'] = 0\n",
    "CN_freesurfer_Out_within1Year = CN_freesurfer_Out_within1Year[CN_freesurfer_Out_within1Year['Label'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Subject</th>\n",
       "      <th>FS_L_ThalamusProper_Vol</th>\n",
       "      <th>FS_L_Caudate_Vol</th>\n",
       "      <th>FS_L_Putamen_Vol</th>\n",
       "      <th>FS_L_Pallidum_Vol</th>\n",
       "      <th>FS_L_Hippo_Vol</th>\n",
       "      <th>FS_L_Amygdala_Vol</th>\n",
       "      <th>FS_L_AccumbensArea_Vol</th>\n",
       "      <th>FS_R_ThalamusProper_Vol</th>\n",
       "      <th>...</th>\n",
       "      <th>FS_R_Superiorfrontal_Area</th>\n",
       "      <th>FS_R_Superiorparietal_Area</th>\n",
       "      <th>FS_R_Superiortemporal_Area</th>\n",
       "      <th>FS_R_Supramarginal_Area</th>\n",
       "      <th>FS_R_Frontalpole_Area</th>\n",
       "      <th>FS_R_Temporalpole_Area</th>\n",
       "      <th>FS_R_Transversetemporal_Area</th>\n",
       "      <th>FS_R_Insula_Area</th>\n",
       "      <th>FS_BrainSeg_Vol_No_Vent_Surf</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>013_S_4595</td>\n",
       "      <td>6823.4</td>\n",
       "      <td>2736.6</td>\n",
       "      <td>4005.4</td>\n",
       "      <td>2279.1</td>\n",
       "      <td>4298.3</td>\n",
       "      <td>1347.9</td>\n",
       "      <td>293.7</td>\n",
       "      <td>6131.6</td>\n",
       "      <td>...</td>\n",
       "      <td>6141.0</td>\n",
       "      <td>5483.0</td>\n",
       "      <td>3414.0</td>\n",
       "      <td>4002.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>2595.0</td>\n",
       "      <td>1.111507e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>014_S_4668</td>\n",
       "      <td>8130.9</td>\n",
       "      <td>4446.9</td>\n",
       "      <td>4364.5</td>\n",
       "      <td>2054.6</td>\n",
       "      <td>4520.2</td>\n",
       "      <td>1443.8</td>\n",
       "      <td>489.5</td>\n",
       "      <td>7925.6</td>\n",
       "      <td>...</td>\n",
       "      <td>8114.0</td>\n",
       "      <td>6438.0</td>\n",
       "      <td>4531.0</td>\n",
       "      <td>4166.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>3117.0</td>\n",
       "      <td>1.166754e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>099_S_2063</td>\n",
       "      <td>6638.6</td>\n",
       "      <td>3619.7</td>\n",
       "      <td>4121.7</td>\n",
       "      <td>2074.0</td>\n",
       "      <td>4175.6</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>482.2</td>\n",
       "      <td>6869.8</td>\n",
       "      <td>...</td>\n",
       "      <td>8498.0</td>\n",
       "      <td>6831.0</td>\n",
       "      <td>3973.0</td>\n",
       "      <td>3874.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3185.0</td>\n",
       "      <td>1.182458e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>023_S_4796</td>\n",
       "      <td>5416.2</td>\n",
       "      <td>2719.3</td>\n",
       "      <td>3774.1</td>\n",
       "      <td>1707.2</td>\n",
       "      <td>3173.9</td>\n",
       "      <td>911.6</td>\n",
       "      <td>417.7</td>\n",
       "      <td>5648.8</td>\n",
       "      <td>...</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>4623.0</td>\n",
       "      <td>3482.0</td>\n",
       "      <td>3479.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>2582.0</td>\n",
       "      <td>9.579232e+05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>127_S_4624</td>\n",
       "      <td>5760.5</td>\n",
       "      <td>3598.7</td>\n",
       "      <td>4508.3</td>\n",
       "      <td>1918.6</td>\n",
       "      <td>3689.0</td>\n",
       "      <td>1422.5</td>\n",
       "      <td>351.0</td>\n",
       "      <td>5317.9</td>\n",
       "      <td>...</td>\n",
       "      <td>6214.0</td>\n",
       "      <td>5004.0</td>\n",
       "      <td>3671.0</td>\n",
       "      <td>3703.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>9.421714e+05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>558</td>\n",
       "      <td>130_S_4294</td>\n",
       "      <td>5250.8</td>\n",
       "      <td>3353.6</td>\n",
       "      <td>3956.6</td>\n",
       "      <td>1616.1</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>1060.2</td>\n",
       "      <td>393.3</td>\n",
       "      <td>4829.9</td>\n",
       "      <td>...</td>\n",
       "      <td>5581.0</td>\n",
       "      <td>4036.0</td>\n",
       "      <td>3085.0</td>\n",
       "      <td>3044.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>2184.0</td>\n",
       "      <td>8.330677e+05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>565</td>\n",
       "      <td>130_S_4542</td>\n",
       "      <td>5401.5</td>\n",
       "      <td>2706.7</td>\n",
       "      <td>3494.4</td>\n",
       "      <td>1735.8</td>\n",
       "      <td>2915.3</td>\n",
       "      <td>1117.6</td>\n",
       "      <td>333.3</td>\n",
       "      <td>5257.6</td>\n",
       "      <td>...</td>\n",
       "      <td>5859.0</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>8.371480e+05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>570</td>\n",
       "      <td>068_S_2194</td>\n",
       "      <td>5721.7</td>\n",
       "      <td>2710.5</td>\n",
       "      <td>3341.8</td>\n",
       "      <td>1739.9</td>\n",
       "      <td>2860.3</td>\n",
       "      <td>1031.1</td>\n",
       "      <td>235.8</td>\n",
       "      <td>5567.9</td>\n",
       "      <td>...</td>\n",
       "      <td>5842.0</td>\n",
       "      <td>4727.0</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>3239.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>8.746831e+05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>578</td>\n",
       "      <td>021_S_4744</td>\n",
       "      <td>5434.1</td>\n",
       "      <td>2914.5</td>\n",
       "      <td>4180.2</td>\n",
       "      <td>1653.1</td>\n",
       "      <td>3474.4</td>\n",
       "      <td>1144.4</td>\n",
       "      <td>496.9</td>\n",
       "      <td>5060.6</td>\n",
       "      <td>...</td>\n",
       "      <td>5649.0</td>\n",
       "      <td>4327.0</td>\n",
       "      <td>2896.0</td>\n",
       "      <td>2875.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>2049.0</td>\n",
       "      <td>8.980089e+05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>581</td>\n",
       "      <td>006_S_4713</td>\n",
       "      <td>7496.5</td>\n",
       "      <td>3328.3</td>\n",
       "      <td>3965.0</td>\n",
       "      <td>2003.5</td>\n",
       "      <td>4536.1</td>\n",
       "      <td>1942.2</td>\n",
       "      <td>389.6</td>\n",
       "      <td>7255.9</td>\n",
       "      <td>...</td>\n",
       "      <td>6386.0</td>\n",
       "      <td>5819.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>1.173105e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     Subject  FS_L_ThalamusProper_Vol  FS_L_Caudate_Vol  \\\n",
       "2             2  013_S_4595                   6823.4            2736.6   \n",
       "12           12  014_S_4668                   8130.9            4446.9   \n",
       "14           14  099_S_2063                   6638.6            3619.7   \n",
       "25           25  023_S_4796                   5416.2            2719.3   \n",
       "26           26  127_S_4624                   5760.5            3598.7   \n",
       "..          ...         ...                      ...               ...   \n",
       "558         558  130_S_4294                   5250.8            3353.6   \n",
       "565         565  130_S_4542                   5401.5            2706.7   \n",
       "570         570  068_S_2194                   5721.7            2710.5   \n",
       "578         578  021_S_4744                   5434.1            2914.5   \n",
       "581         581  006_S_4713                   7496.5            3328.3   \n",
       "\n",
       "     FS_L_Putamen_Vol  FS_L_Pallidum_Vol  FS_L_Hippo_Vol  FS_L_Amygdala_Vol  \\\n",
       "2              4005.4             2279.1          4298.3             1347.9   \n",
       "12             4364.5             2054.6          4520.2             1443.8   \n",
       "14             4121.7             2074.0          4175.6             1756.0   \n",
       "25             3774.1             1707.2          3173.9              911.6   \n",
       "26             4508.3             1918.6          3689.0             1422.5   \n",
       "..                ...                ...             ...                ...   \n",
       "558            3956.6             1616.1          2506.0             1060.2   \n",
       "565            3494.4             1735.8          2915.3             1117.6   \n",
       "570            3341.8             1739.9          2860.3             1031.1   \n",
       "578            4180.2             1653.1          3474.4             1144.4   \n",
       "581            3965.0             2003.5          4536.1             1942.2   \n",
       "\n",
       "     FS_L_AccumbensArea_Vol  FS_R_ThalamusProper_Vol  ...  \\\n",
       "2                     293.7                   6131.6  ...   \n",
       "12                    489.5                   7925.6  ...   \n",
       "14                    482.2                   6869.8  ...   \n",
       "25                    417.7                   5648.8  ...   \n",
       "26                    351.0                   5317.9  ...   \n",
       "..                      ...                      ...  ...   \n",
       "558                   393.3                   4829.9  ...   \n",
       "565                   333.3                   5257.6  ...   \n",
       "570                   235.8                   5567.9  ...   \n",
       "578                   496.9                   5060.6  ...   \n",
       "581                   389.6                   7255.9  ...   \n",
       "\n",
       "     FS_R_Superiorfrontal_Area  FS_R_Superiorparietal_Area  \\\n",
       "2                       6141.0                      5483.0   \n",
       "12                      8114.0                      6438.0   \n",
       "14                      8498.0                      6831.0   \n",
       "25                      6111.0                      4623.0   \n",
       "26                      6214.0                      5004.0   \n",
       "..                         ...                         ...   \n",
       "558                     5581.0                      4036.0   \n",
       "565                     5859.0                      4230.0   \n",
       "570                     5842.0                      4727.0   \n",
       "578                     5649.0                      4327.0   \n",
       "581                     6386.0                      5819.0   \n",
       "\n",
       "     FS_R_Superiortemporal_Area  FS_R_Supramarginal_Area  \\\n",
       "2                        3414.0                   4002.0   \n",
       "12                       4531.0                   4166.0   \n",
       "14                       3973.0                   3874.0   \n",
       "25                       3482.0                   3479.0   \n",
       "26                       3671.0                   3703.0   \n",
       "..                          ...                      ...   \n",
       "558                      3085.0                   3044.0   \n",
       "565                      3102.0                   2939.0   \n",
       "570                      2980.0                   3239.0   \n",
       "578                      2896.0                   2875.0   \n",
       "581                      4200.0                   3861.0   \n",
       "\n",
       "     FS_R_Frontalpole_Area  FS_R_Temporalpole_Area  \\\n",
       "2                    254.0                   489.0   \n",
       "12                   352.0                   498.0   \n",
       "14                   350.0                   536.0   \n",
       "25                   258.0                   390.0   \n",
       "26                   289.0                   488.0   \n",
       "..                     ...                     ...   \n",
       "558                  302.0                   379.0   \n",
       "565                  283.0                   431.0   \n",
       "570                  281.0                   410.0   \n",
       "578                  301.0                   421.0   \n",
       "581                  269.0                   500.0   \n",
       "\n",
       "     FS_R_Transversetemporal_Area  FS_R_Insula_Area  \\\n",
       "2                           362.0            2595.0   \n",
       "12                          404.0            3117.0   \n",
       "14                          371.0            3185.0   \n",
       "25                          321.0            2582.0   \n",
       "26                          328.0            2211.0   \n",
       "..                            ...               ...   \n",
       "558                         268.0            2184.0   \n",
       "565                         293.0            2210.0   \n",
       "570                         289.0            2194.0   \n",
       "578                         277.0            2049.0   \n",
       "581                         288.0            2145.0   \n",
       "\n",
       "     FS_BrainSeg_Vol_No_Vent_Surf  Label  \n",
       "2                    1.111507e+06      1  \n",
       "12                   1.166754e+06      1  \n",
       "14                   1.182458e+06      1  \n",
       "25                   9.579232e+05      1  \n",
       "26                   9.421714e+05      1  \n",
       "..                            ...    ...  \n",
       "558                  8.330677e+05      1  \n",
       "565                  8.371480e+05      1  \n",
       "570                  8.746831e+05      1  \n",
       "578                  8.980089e+05      1  \n",
       "581                  1.173105e+06      1  \n",
       "\n",
       "[134 rows x 222 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCI_freesurfer_Out_within1Year[MCI_freesurfer_Out_within1Year['Label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "volAndCN_data = pd.concat([CN_freesurfer_Out, volner], axis=0, sort=False)\n",
    "# volAndCN_data = volAndCN_data.dropna()\n",
    "volAndMCI_data = pd.concat([MCI_freesurfer_Out, volner], axis=0, sort=False)\n",
    "# volAndMCI_data = volAndMCI_data.dropna()\n",
    "volAndAD_data = pd.concat([AD_freesurfer_Out, volner], axis=0, sort=False)\n",
    "# volAndAD_data = volAndAD_data.dropna()\n",
    "AD_MCI_freesurfer_Out_within1Year = pd.concat([AD_freesurfer_Out_within1Year, MCI_freesurfer_Out_within1Year], axis=0, sort=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Subject</th>\n",
       "      <th>FS_L_ThalamusProper_Vol</th>\n",
       "      <th>FS_L_Caudate_Vol</th>\n",
       "      <th>FS_L_Putamen_Vol</th>\n",
       "      <th>FS_L_Pallidum_Vol</th>\n",
       "      <th>FS_L_Hippo_Vol</th>\n",
       "      <th>FS_L_Amygdala_Vol</th>\n",
       "      <th>FS_L_AccumbensArea_Vol</th>\n",
       "      <th>FS_R_ThalamusProper_Vol</th>\n",
       "      <th>...</th>\n",
       "      <th>FS_L_WM_Hypointens_Vol</th>\n",
       "      <th>FS_R_WM_Hypointens_Vol</th>\n",
       "      <th>FS_L_Non-WM_Hypointens_Vol</th>\n",
       "      <th>FS_R_Non-WM_Hypointens_Vol</th>\n",
       "      <th>FS_OpticChiasm_Vol</th>\n",
       "      <th>FS_CC_Posterior_Vol</th>\n",
       "      <th>FS_CC_MidPosterior_Vol</th>\n",
       "      <th>FS_CC_Central_Vol</th>\n",
       "      <th>FS_CC_MidAnterior_Vol</th>\n",
       "      <th>FS_CC_Anterior_Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>037_S_4071</td>\n",
       "      <td>7524.5</td>\n",
       "      <td>4313.9</td>\n",
       "      <td>4709.2</td>\n",
       "      <td>2411.9</td>\n",
       "      <td>4141.2</td>\n",
       "      <td>1453.2</td>\n",
       "      <td>303.6</td>\n",
       "      <td>7778.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>018_S_4400</td>\n",
       "      <td>7040.7</td>\n",
       "      <td>2889.0</td>\n",
       "      <td>4192.5</td>\n",
       "      <td>1805.1</td>\n",
       "      <td>3917.6</td>\n",
       "      <td>1660.1</td>\n",
       "      <td>390.7</td>\n",
       "      <td>6533.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>029_S_4290</td>\n",
       "      <td>6034.1</td>\n",
       "      <td>3711.6</td>\n",
       "      <td>4222.0</td>\n",
       "      <td>2110.8</td>\n",
       "      <td>3113.6</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>439.5</td>\n",
       "      <td>5530.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>029_S_4652</td>\n",
       "      <td>6008.3</td>\n",
       "      <td>2884.1</td>\n",
       "      <td>3715.7</td>\n",
       "      <td>1612.7</td>\n",
       "      <td>3478.3</td>\n",
       "      <td>1190.9</td>\n",
       "      <td>457.1</td>\n",
       "      <td>5293.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>031_S_4474</td>\n",
       "      <td>6948.1</td>\n",
       "      <td>3291.7</td>\n",
       "      <td>3953.5</td>\n",
       "      <td>1728.6</td>\n",
       "      <td>3193.5</td>\n",
       "      <td>1227.4</td>\n",
       "      <td>469.7</td>\n",
       "      <td>6342.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>992774</td>\n",
       "      <td>8416.0</td>\n",
       "      <td>3756.0</td>\n",
       "      <td>5080.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>1473.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>6862.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>1004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>NaN</td>\n",
       "      <td>993675</td>\n",
       "      <td>7477.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>4874.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>4571.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>6879.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>NaN</td>\n",
       "      <td>994273</td>\n",
       "      <td>8416.0</td>\n",
       "      <td>4236.0</td>\n",
       "      <td>5961.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>4159.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>8228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>NaN</td>\n",
       "      <td>995174</td>\n",
       "      <td>9334.0</td>\n",
       "      <td>4546.0</td>\n",
       "      <td>6769.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>4616.0</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>8032.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>NaN</td>\n",
       "      <td>996782</td>\n",
       "      <td>8793.0</td>\n",
       "      <td>4432.0</td>\n",
       "      <td>6086.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>5133.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>7665.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>938.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     Subject  FS_L_ThalamusProper_Vol  FS_L_Caudate_Vol  \\\n",
       "0            0.0  037_S_4071                   7524.5            4313.9   \n",
       "1            1.0  018_S_4400                   7040.7            2889.0   \n",
       "2            2.0  029_S_4290                   6034.1            3711.6   \n",
       "3            3.0  029_S_4652                   6008.3            2884.1   \n",
       "4            4.0  031_S_4474                   6948.1            3291.7   \n",
       "...          ...         ...                      ...               ...   \n",
       "1201         NaN      992774                   8416.0            3756.0   \n",
       "1202         NaN      993675                   7477.0            3449.0   \n",
       "1203         NaN      994273                   8416.0            4236.0   \n",
       "1204         NaN      995174                   9334.0            4546.0   \n",
       "1205         NaN      996782                   8793.0            4432.0   \n",
       "\n",
       "      FS_L_Putamen_Vol  FS_L_Pallidum_Vol  FS_L_Hippo_Vol  FS_L_Amygdala_Vol  \\\n",
       "0               4709.2             2411.9          4141.2             1453.2   \n",
       "1               4192.5             1805.1          3917.6             1660.1   \n",
       "2               4222.0             2110.8          3113.6             1434.0   \n",
       "3               3715.7             1612.7          3478.3             1190.9   \n",
       "4               3953.5             1728.6          3193.5             1227.4   \n",
       "...                ...                ...             ...                ...   \n",
       "1201            5080.0             1188.0          4250.0             1473.0   \n",
       "1202            4874.0             1054.0          4571.0             1358.0   \n",
       "1203            5961.0             1364.0          4159.0             1627.0   \n",
       "1204            6769.0             1497.0          4616.0             1629.0   \n",
       "1205            6086.0             1364.0          5133.0             1605.0   \n",
       "\n",
       "      FS_L_AccumbensArea_Vol  FS_R_ThalamusProper_Vol  ...  \\\n",
       "0                      303.6                   7778.8  ...   \n",
       "1                      390.7                   6533.8  ...   \n",
       "2                      439.5                   5530.9  ...   \n",
       "3                      457.1                   5293.9  ...   \n",
       "4                      469.7                   6342.0  ...   \n",
       "...                      ...                      ...  ...   \n",
       "1201                   538.0                   6862.0  ...   \n",
       "1202                   564.0                   6879.0  ...   \n",
       "1203                   700.0                   8228.0  ...   \n",
       "1204                   535.0                   8032.0  ...   \n",
       "1205                   726.0                   7665.0  ...   \n",
       "\n",
       "      FS_L_WM_Hypointens_Vol  FS_R_WM_Hypointens_Vol  \\\n",
       "0                        NaN                     NaN   \n",
       "1                        NaN                     NaN   \n",
       "2                        NaN                     NaN   \n",
       "3                        NaN                     NaN   \n",
       "4                        NaN                     NaN   \n",
       "...                      ...                     ...   \n",
       "1201                     0.0                     0.0   \n",
       "1202                     0.0                     0.0   \n",
       "1203                     0.0                     0.0   \n",
       "1204                     0.0                     0.0   \n",
       "1205                     0.0                     0.0   \n",
       "\n",
       "      FS_L_Non-WM_Hypointens_Vol  FS_R_Non-WM_Hypointens_Vol  \\\n",
       "0                            NaN                         NaN   \n",
       "1                            NaN                         NaN   \n",
       "2                            NaN                         NaN   \n",
       "3                            NaN                         NaN   \n",
       "4                            NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "1201                         0.0                         0.0   \n",
       "1202                         0.0                         0.0   \n",
       "1203                         0.0                         0.0   \n",
       "1204                         0.0                         0.0   \n",
       "1205                         0.0                         0.0   \n",
       "\n",
       "      FS_OpticChiasm_Vol  FS_CC_Posterior_Vol  FS_CC_MidPosterior_Vol  \\\n",
       "0                    NaN                  NaN                     NaN   \n",
       "1                    NaN                  NaN                     NaN   \n",
       "2                    NaN                  NaN                     NaN   \n",
       "3                    NaN                  NaN                     NaN   \n",
       "4                    NaN                  NaN                     NaN   \n",
       "...                  ...                  ...                     ...   \n",
       "1201               224.0                971.0                   458.0   \n",
       "1202               107.0                702.0                   269.0   \n",
       "1203               232.0                908.0                   339.0   \n",
       "1204               142.0                765.0                   441.0   \n",
       "1205               172.0                753.0                   495.0   \n",
       "\n",
       "      FS_CC_Central_Vol  FS_CC_MidAnterior_Vol  FS_CC_Anterior_Vol  \n",
       "0                   NaN                    NaN                 NaN  \n",
       "1                   NaN                    NaN                 NaN  \n",
       "2                   NaN                    NaN                 NaN  \n",
       "3                   NaN                    NaN                 NaN  \n",
       "4                   NaN                    NaN                 NaN  \n",
       "...                 ...                    ...                 ...  \n",
       "1201              416.0                  415.0              1004.0  \n",
       "1202              306.0                  319.0               660.0  \n",
       "1203              368.0                  414.0               741.0  \n",
       "1204              458.0                  424.0               863.0  \n",
       "1205              666.0                  511.0               938.0  \n",
       "\n",
       "[1255 rows x 270 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volAndCN_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['FS_L_ThalamusProper_Vol', 'FS_L_Caudate_Vol', 'FS_L_Putamen_Vol', 'FS_L_Pallidum_Vol', \n",
    "            'FS_L_Hippo_Vol', 'FS_L_Amygdala_Vol', 'FS_L_AccumbensArea_Vol', 'FS_R_ThalamusProper_Vol', \n",
    "            'FS_R_Caudate_Vol', 'FS_R_Putamen_Vol', 'FS_R_Pallidum_Vol', 'FS_R_Hippo_Vol', 'FS_R_Amygdala_Vol', \n",
    "            'FS_R_AccumbensArea_Vol', 'FS_L_Bankssts_Thck', 'FS_L_Caudalanteriorcingulate_Thck', \n",
    "            'FS_L_Caudalmiddlefrontal_Thck', 'FS_L_Cuneus_Thck', 'FS_L_Entorhinal_Thck', 'FS_L_Fusiform_Thck', \n",
    "            'FS_L_Inferiorparietal_Thck', 'FS_L_Inferiortemporal_Thck', 'FS_L_Isthmuscingulate_Thck', \n",
    "            'FS_L_Lateraloccipital_Thck', 'FS_L_Lateralorbitofrontal_Thck', 'FS_L_Lingual_Thck', \n",
    "            'FS_L_Medialorbitofrontal_Thck', 'FS_L_Middletemporal_Thck', 'FS_L_Parahippocampal_Thck', \n",
    "            'FS_L_Paracentral_Thck', 'FS_L_Parsopercularis_Thck', 'FS_L_Parsorbitalis_Thck', \n",
    "            'FS_L_Parstriangularis_Thck', 'FS_L_Pericalcarine_Thck', 'FS_L_Postcentral_Thck', \n",
    "            'FS_L_Posteriorcingulate_Thck', 'FS_L_Precentral_Thck', 'FS_L_Precuneus_Thck', \n",
    "            'FS_L_Rostralanteriorcingulate_Thck', 'FS_L_Rostralmiddlefrontal_Thck', 'FS_L_Superiorfrontal_Thck', \n",
    "            'FS_L_Superiorparietal_Thck', 'FS_L_Superiortemporal_Thck', 'FS_L_Supramarginal_Thck', \n",
    "            'FS_L_Frontalpole_Thck', 'FS_L_Temporalpole_Thck', 'FS_L_Transversetemporal_Thck', \n",
    "            'FS_L_Insula_Thck', 'FS_R_Bankssts_Thck', 'FS_R_Caudalanteriorcingulate_Thck', \n",
    "            'FS_R_Caudalmiddlefrontal_Thck', 'FS_R_Cuneus_Thck', 'FS_R_Entorhinal_Thck', 'FS_R_Fusiform_Thck', \n",
    "            'FS_R_Inferiorparietal_Thck', 'FS_R_Inferiortemporal_Thck', 'FS_R_Isthmuscingulate_Thck', \n",
    "            'FS_R_Lateraloccipital_Thck', 'FS_R_Lateralorbitofrontal_Thck', 'FS_R_Lingual_Thck', \n",
    "            'FS_R_Medialorbitofrontal_Thck', 'FS_R_Middletemporal_Thck', 'FS_R_Parahippocampal_Thck', \n",
    "            'FS_R_Paracentral_Thck', 'FS_R_Parsopercularis_Thck', 'FS_R_Parsorbitalis_Thck', \n",
    "            'FS_R_Parstriangularis_Thck', 'FS_R_Pericalcarine_Thck', 'FS_R_Postcentral_Thck', \n",
    "            'FS_R_Posteriorcingulate_Thck', 'FS_R_Precentral_Thck', 'FS_R_Precuneus_Thck', \n",
    "            'FS_R_Rostralanteriorcingulate_Thck', 'FS_R_Rostralmiddlefrontal_Thck', \n",
    "            'FS_R_Superiorfrontal_Thck', 'FS_R_Superiorparietal_Thck', 'FS_R_Superiortemporal_Thck',\n",
    "            'FS_R_Supramarginal_Thck', 'FS_R_Frontalpole_Thck', 'FS_R_Temporalpole_Thck', \n",
    "            'FS_R_Transversetemporal_Thck', 'FS_R_Insula_Thck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureOnlyVol = ['FS_L_ThalamusProper_Vol', 'FS_L_Caudate_Vol', 'FS_L_Putamen_Vol', 'FS_L_Pallidum_Vol', \n",
    "            'FS_L_Hippo_Vol', 'FS_L_Amygdala_Vol', 'FS_L_AccumbensArea_Vol', 'FS_R_ThalamusProper_Vol', \n",
    "            'FS_R_Caudate_Vol', 'FS_R_Putamen_Vol', 'FS_R_Pallidum_Vol', 'FS_R_Hippo_Vol', 'FS_R_Amygdala_Vol', \n",
    "            'FS_R_AccumbensArea_Vol', 'FS_L_bankssts_Vol', 'FS_L_caudalanteriorcingulate_Vol', \n",
    "            'FS_L_caudalmiddlefrontal_Vol', 'FS_L_cuneus_Vol', 'FS_L_entorhinal_Vol', 'FS_L_fusiform_Vol', \n",
    "            'FS_L_inferiorparietal_Vol', 'FS_L_inferiortemporal_Vol', 'FS_L_isthmuscingulate_Vol', \n",
    "            'FS_L_lateraloccipital_Vol', 'FS_L_lateralorbitofrontal_Vol', 'FS_L_lingual_Vol', \n",
    "            'FS_L_medialorbitofrontal_Vol', 'FS_L_middletemporal_Vol', 'FS_L_parahippocampal_Vol', \n",
    "            'FS_L_paracentral_Vol', 'FS_L_parsopercularis_Vol', 'FS_L_parsorbitalis_Vol', \n",
    "            'FS_L_parstriangularis_Vol', 'FS_L_pericalcarine_Vol', 'FS_L_postcentral_Vol', \n",
    "            'FS_L_posteriorcingulate_Vol', 'FS_L_precentral_Vol', 'FS_L_precuneus_Vol', \n",
    "            'FS_L_rostralanteriorcingulate_Vol', 'FS_L_rostralmiddlefrontal_Vol', 'FS_L_superiorfrontal_Vol', \n",
    "            'FS_L_superiorparietal_Vol', 'FS_L_superiortemporal_Vol', 'FS_L_supramarginal_Vol', \n",
    "            'FS_L_frontalpole_Vol', 'FS_L_temporalpole_Vol', 'FS_L_transversetemporal_Vol', \n",
    "            'FS_L_insula_Vol', 'FS_R_bankssts_Vol', 'FS_R_caudalanteriorcingulate_Vol', \n",
    "            'FS_R_caudalmiddlefrontal_Vol', 'FS_R_cuneus_Vol', 'FS_R_entorhinal_Vol', 'FS_R_fusiform_Vol', \n",
    "            'FS_R_inferiorparietal_Vol', 'FS_R_inferiortemporal_Vol', 'FS_R_isthmuscingulate_Vol', \n",
    "            'FS_R_lateraloccipital_Vol', 'FS_R_lateralorbitofrontal_Vol', 'FS_R_lingual_Vol', \n",
    "            'FS_R_medialorbitofrontal_Vol', 'FS_R_middletemporal_Vol', 'FS_R_parahippocampal_Vol', \n",
    "            'FS_R_paracentral_Vol', 'FS_R_parsopercularis_Vol', 'FS_R_parsorbitalis_Vol', \n",
    "            'FS_R_parstriangularis_Vol', 'FS_R_pericalcarine_Vol', 'FS_R_postcentral_Vol', \n",
    "            'FS_R_posteriorcingulate_Vol', 'FS_R_precentral_Vol', 'FS_R_precuneus_Vol', \n",
    "            'FS_R_rostralanteriorcingulate_Vol', 'FS_R_rostralmiddlefrontal_Vol', \n",
    "            'FS_R_superiorfrontal_Vol', 'FS_R_superiorparietal_Vol', 'FS_R_superiortemporal_Vol',\n",
    "            'FS_R_supramarginal_Vol', 'FS_R_frontalpole_Vol', 'FS_R_temporalpole_Vol', \n",
    "            'FS_R_transversetemporal_Vol', 'FS_R_insula_Vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_OCFHippo = ['FS_R_Lateraloccipital_Thck','FS_R_Lingual_Thck','FS_R_Cuneus_Thck',\n",
    "                    'FS_R_Pericalcarine_Thck','FS_R_Superiorparietal_Thck',\n",
    "                    'FS_R_Inferiorparietal_Thck','FS_R_Supramarginal_Thck',\n",
    "                    'FS_R_Postcentral_Thck','FS_R_Precuneus_Thck','FS_R_Superiorfrontal_Thck',\n",
    "                    'FS_R_Rostralmiddlefrontal_Thck','FS_R_Caudalmiddlefrontal_Thck',\n",
    "                    'FS_R_Parsopercularis_Thck','FS_R_Parstriangularis_Thck','FS_R_Parsorbitalis_Thck',\n",
    "                    'FS_R_Lateralorbitofrontal_Thck','FS_R_Medialorbitofrontal_Thck',\n",
    "                    'FS_R_Precentral_Thck','FS_R_Paracentral_Thck','FS_R_Frontalpole_Thck',\n",
    "                    'FS_L_Hippo_Vol','FS_R_Hippo_Vol','FS_L_Lateraloccipital_Thck',\n",
    "                    'FS_L_Lingual_Thck','FS_L_Cuneus_Thck','FS_L_Pericalcarine_Thck',\n",
    "                    'FS_L_Superiorparietal_Thck','FS_L_Inferiorparietal_Thck','FS_L_Supramarginal_Thck',\n",
    "                    'FS_L_Postcentral_Thck','FS_L_Precuneus_Thck','FS_L_Superiorfrontal_Thck',\n",
    "                    'FS_L_Rostralmiddlefrontal_Thck','FS_L_Caudalmiddlefrontal_Thck',\n",
    "                    'FS_L_Parsopercularis_Thck','FS_L_Parstriangularis_Thck','FS_L_Parsorbitalis_Thck',\n",
    "                    'FS_L_Lateralorbitofrontal_Thck','FS_L_Medialorbitofrontal_Thck',\n",
    "                    'FS_L_Precentral_Thck','FS_L_Paracentral_Thck','FS_L_Frontalpole_Thck']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert pd.Dataframe(anyInput) to feature(np.array) here ## with label here\n",
    "def Convert2FeatureVectorWithLabel(pdFrame,features):\n",
    "    subject = []\n",
    "    pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'] = 1.0 / pdFrame['FS_BrainSeg_Vol_No_Vent_Surf']\n",
    "    X = []\n",
    "    x =[]\n",
    "    weighted_mean_feature_dict = {}\n",
    "    for feature in features:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame[feature_area]).sum() / pdFrame[feature_area].sum()\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf']).sum() / pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'].sum()   \n",
    "    variance_feature_dict = {}\n",
    "    for feature in features:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[feature_area] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[feature_area].sum() - (np.square(pdFrame[feature_area])).sum() / pdFrame[feature_area].sum()))\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum() - (np.square(pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"])).sum() / pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum()))\n",
    "    for index,row in pdFrame.iterrows():\n",
    "        for feature in features:\n",
    "            x.append((np.float(row[feature]) - weighted_mean_feature_dict[feature]) / variance_feature_dict[feature])\n",
    "        subject.append(row['Subject'])\n",
    "        x.append(row['Label'])\n",
    "        X.append(x)\n",
    "        x =[]\n",
    "        if len(X) % 100 == 0:\n",
    "            pass\n",
    "    X = np.array(X)\n",
    "    return X, subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert pd.Dataframe(Only Vol) to feature(np.array) here ## with label here\n",
    "def Convert2FeatureVolOnlyVectorWithLabel(pdFrame):\n",
    "    subject = []\n",
    "    pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'] = 1.0 / pdFrame['FS_BrainSeg_Vol_No_Vent_Surf']\n",
    "    X = []\n",
    "    x =[]\n",
    "    weighted_mean_feature_dict = {}\n",
    "    for feature in featureOnlyVol:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame[feature_area]).sum() / pdFrame[feature_area].sum()\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf']).sum() / pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'].sum()   \n",
    "    variance_feature_dict = {}\n",
    "    for feature in featureOnlyVol:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[feature_area] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[feature_area].sum() - (np.square(pdFrame[feature_area])).sum() / pdFrame[feature_area].sum()))\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum() - (np.square(pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"])).sum() / pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum()))\n",
    "    for index,row in pdFrame.iterrows():\n",
    "        for feature in featureOnlyVol:\n",
    "            x.append((np.float(row[feature]) - weighted_mean_feature_dict[feature]) / variance_feature_dict[feature])\n",
    "        subject.append(row['Subject'])\n",
    "        x.append(row['Label'])\n",
    "        X.append(x)\n",
    "        x =[]\n",
    "        if len(X) % 100 == 0:\n",
    "            pass\n",
    "    X = np.array(X)\n",
    "    return X, subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert pd.Dataframe(with Vol and Thck) to feature(np.array) here ## with label here\n",
    "def Convert2FeatureVolThckVectorWithLabel(pdFrame):\n",
    "    subject = []\n",
    "    pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'] = 1.0 / pdFrame['FS_BrainSeg_Vol_No_Vent_Surf']\n",
    "    X = []\n",
    "    x =[]\n",
    "    weighted_mean_feature_dict = {}\n",
    "    for feature in features:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame[feature_area]).sum() / pdFrame[feature_area].sum()\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf']).sum() / pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'].sum()   \n",
    "    variance_feature_dict = {}\n",
    "    for feature in features:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[feature_area] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[feature_area].sum() - (np.square(pdFrame[feature_area])).sum() / pdFrame[feature_area].sum()))\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum() - (np.square(pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"])).sum() / pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum()))\n",
    "    for index,row in pdFrame.iterrows():\n",
    "        for feature in features:\n",
    "            x.append((np.float(row[feature]) - weighted_mean_feature_dict[feature]) / variance_feature_dict[feature])\n",
    "        subject.append(row['Subject'])\n",
    "        x.append(row['Label'])\n",
    "        X.append(x)\n",
    "        x =[]\n",
    "        if len(X) % 100 == 0:\n",
    "            pass\n",
    "    X = np.array(X)\n",
    "    return X, subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529, 83)\n",
      "(529, 82) (529,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6037735849056604"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vector_with_Label, Vector_subject = Convert2FeatureVolThckVectorWithLabel(AD_MCI_freesurfer_Out_within1Year)\n",
    "print(Vector_with_Label.shape)\n",
    "\n",
    "print(Vector_with_Label[:,0:-1].shape,Vector_with_Label[:,-1].shape)\n",
    "X = Vector_with_Label[:,0:-1]\n",
    "y = Vector_with_Label[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(6,2), random_state=1,max_iter=700)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(394, 83)\n",
      "(394, 82) (394,)\n",
      "Epoch 1/10\n",
      "275/275 [==============================] - 0s 860us/step - loss: 0.7431 - accuracy: 0.4764\n",
      "Epoch 2/10\n",
      "275/275 [==============================] - 0s 290us/step - loss: 0.6578 - accuracy: 0.6255\n",
      "Epoch 3/10\n",
      "275/275 [==============================] - 0s 288us/step - loss: 0.6297 - accuracy: 0.6509\n",
      "Epoch 4/10\n",
      "275/275 [==============================] - 0s 318us/step - loss: 0.6073 - accuracy: 0.6909\n",
      "Epoch 5/10\n",
      "275/275 [==============================] - 0s 286us/step - loss: 0.5858 - accuracy: 0.6945\n",
      "Epoch 6/10\n",
      "275/275 [==============================] - 0s 294us/step - loss: 0.5638 - accuracy: 0.7200\n",
      "Epoch 7/10\n",
      "275/275 [==============================] - 0s 289us/step - loss: 0.5489 - accuracy: 0.7200\n",
      "Epoch 8/10\n",
      "275/275 [==============================] - 0s 331us/step - loss: 0.5255 - accuracy: 0.7673\n",
      "Epoch 9/10\n",
      "275/275 [==============================] - 0s 270us/step - loss: 0.5081 - accuracy: 0.7491\n",
      "Epoch 10/10\n",
      "275/275 [==============================] - 0s 281us/step - loss: 0.4874 - accuracy: 0.7818\n",
      "119/119 [==============================] - 0s 263us/step\n",
      "Accuracy: 60.50\n"
     ]
    }
   ],
   "source": [
    "Vector_with_Label, Vector_subject = Convert2FeatureVolOnlyVectorWithLabel(MCI_freesurfer_Out_within1Year)\n",
    "print(Vector_with_Label.shape)\n",
    "print(Vector_with_Label[:,0:-1].shape,Vector_with_Label[:,-1].shape)\n",
    "X = Vector_with_Label[:,0:-1]\n",
    "y = Vector_with_Label[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=82, activation='relu'))\n",
    "model.add(Dense(4, activation='relu',name = 'my_layer'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=5)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 43)\n",
      "(729, 42) (729,)\n",
      "Epoch 1/15\n",
      "510/510 [==============================] - 0s 683us/step - loss: 0.6934 - accuracy: 0.5392\n",
      "Epoch 2/15\n",
      "510/510 [==============================] - 0s 341us/step - loss: 0.6177 - accuracy: 0.6647\n",
      "Epoch 3/15\n",
      "510/510 [==============================] - 0s 341us/step - loss: 0.5917 - accuracy: 0.6824\n",
      "Epoch 4/15\n",
      "510/510 [==============================] - 0s 292us/step - loss: 0.5739 - accuracy: 0.7039\n",
      "Epoch 5/15\n",
      "510/510 [==============================] - 0s 330us/step - loss: 0.5564 - accuracy: 0.7373\n",
      "Epoch 6/15\n",
      "510/510 [==============================] - 0s 300us/step - loss: 0.5457 - accuracy: 0.7510\n",
      "Epoch 7/15\n",
      "510/510 [==============================] - 0s 316us/step - loss: 0.5295 - accuracy: 0.7686\n",
      "Epoch 8/15\n",
      "510/510 [==============================] - 0s 323us/step - loss: 0.5236 - accuracy: 0.7588\n",
      "Epoch 9/15\n",
      "510/510 [==============================] - 0s 300us/step - loss: 0.5053 - accuracy: 0.7863\n",
      "Epoch 10/15\n",
      "510/510 [==============================] - 0s 329us/step - loss: 0.4987 - accuracy: 0.7804\n",
      "Epoch 11/15\n",
      "510/510 [==============================] - 0s 305us/step - loss: 0.4862 - accuracy: 0.7882\n",
      "Epoch 12/15\n",
      "510/510 [==============================] - 0s 360us/step - loss: 0.4783 - accuracy: 0.7863\n",
      "Epoch 13/15\n",
      "510/510 [==============================] - 0s 344us/step - loss: 0.4666 - accuracy: 0.7980\n",
      "Epoch 14/15\n",
      "510/510 [==============================] - 0s 301us/step - loss: 0.4573 - accuracy: 0.8078\n",
      "Epoch 15/15\n",
      "510/510 [==============================] - 0s 322us/step - loss: 0.4483 - accuracy: 0.7961\n",
      "219/219 [==============================] - 0s 165us/step\n",
      "Accuracy: 69.86\n"
     ]
    }
   ],
   "source": [
    "Vector_with_Label, Vector_subject = Convert2FeatureVectorWithLabel(AD_MCI_freesurfer_Out_within1Year,feature_OCFHippo)\n",
    "print(Vector_with_Label.shape)\n",
    "print(Vector_with_Label[:,0:-1].shape,Vector_with_Label[:,-1].shape)\n",
    "X = Vector_with_Label[:,0:-1]\n",
    "y = Vector_with_Label[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=Vector_with_Label.shape[1] - 1, activation='relu'))\n",
    "model.add(Dense(8, activation='relu',name = 'my_layer'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=5)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#该函数用来提取中间层的特征，即中间神经元的输出\n",
    "def clusterFeatureExtractor(data_with_volner,data_without_volner):\n",
    "    Vector_with_Label, Vector_subject = Convert2FeatureVolThckVectorWithLabel(data_with_volner)\n",
    "    Vector_without_volner_with_Label, Vector_without_volner_Vector_subject = Convert2FeatureVectorWithLabel(data_without_volner)\n",
    "    print(Vector_with_Label.shape)\n",
    "    print(Vector_with_Label[:,0:-1].shape,Vector_with_Label[:,-1].shape)\n",
    "    X = Vector_with_Label[:,0:-1]\n",
    "    y = Vector_with_Label[:,-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=82, activation='relu'))\n",
    "    model.add(Dense(6, activation='relu',name = 'my_layer'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train, y_train, epochs=15, batch_size=10)\n",
    "    # evaluate the keras model\n",
    "    _, accuracy = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy: %.2f' % (accuracy*100))\n",
    "    layer_name = 'my_layer'\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    intermediate_output = intermediate_layer_model.predict(Vector_without_volner_with_Label[:,0:-1])\n",
    "    print(intermediate_output.shape)\n",
    "    return intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "(1255, 83)\n",
      "(1255, 82) (1255,)\n",
      "Epoch 1/15\n",
      "878/878 [==============================] - 0s 312us/step - loss: 0.7669 - accuracy: 0.4806\n",
      "Epoch 2/15\n",
      "878/878 [==============================] - 0s 131us/step - loss: 0.3288 - accuracy: 0.9339\n",
      "Epoch 3/15\n",
      "878/878 [==============================] - 0s 137us/step - loss: 0.1581 - accuracy: 0.9841\n",
      "Epoch 4/15\n",
      "878/878 [==============================] - 0s 129us/step - loss: 0.0948 - accuracy: 0.9886\n",
      "Epoch 5/15\n",
      "878/878 [==============================] - 0s 134us/step - loss: 0.0600 - accuracy: 0.9966\n",
      "Epoch 6/15\n",
      "878/878 [==============================] - 0s 130us/step - loss: 0.0403 - accuracy: 0.9977\n",
      "Epoch 7/15\n",
      "878/878 [==============================] - 0s 139us/step - loss: 0.0286 - accuracy: 0.9989\n",
      "Epoch 8/15\n",
      "878/878 [==============================] - 0s 133us/step - loss: 0.0203 - accuracy: 0.9989\n",
      "Epoch 9/15\n",
      "878/878 [==============================] - 0s 139us/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "878/878 [==============================] - 0s 132us/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "878/878 [==============================] - 0s 132us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "878/878 [==============================] - 0s 134us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "878/878 [==============================] - 0s 135us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "878/878 [==============================] - 0s 132us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "878/878 [==============================] - 0s 134us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "377/377 [==============================] - 0s 86us/step\n",
      "Accuracy: 99.73\n",
      "(142, 6)\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "(1694, 83)\n",
      "(1694, 82) (1694,)\n",
      "Epoch 1/15\n",
      "1185/1185 [==============================] - 0s 266us/step - loss: 0.1864 - accuracy: 0.9544\n",
      "Epoch 2/15\n",
      "1185/1185 [==============================] - 0s 137us/step - loss: 0.0583 - accuracy: 0.9941\n",
      "Epoch 3/15\n",
      "1185/1185 [==============================] - 0s 135us/step - loss: 0.0289 - accuracy: 0.9958\n",
      "Epoch 4/15\n",
      "1185/1185 [==============================] - 0s 135us/step - loss: 0.0163 - accuracy: 0.9975\n",
      "Epoch 5/15\n",
      "1185/1185 [==============================] - 0s 134us/step - loss: 0.0102 - accuracy: 0.9992\n",
      "Epoch 6/15\n",
      "1185/1185 [==============================] - 0s 134us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "1185/1185 [==============================] - 0s 139us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "1185/1185 [==============================] - 0s 133us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "1185/1185 [==============================] - 0s 134us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "1185/1185 [==============================] - 0s 134us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "1185/1185 [==============================] - 0s 137us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "1185/1185 [==============================] - 0s 135us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "1185/1185 [==============================] - 0s 135us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "1185/1185 [==============================] - 0s 141us/step - loss: 9.8825e-04 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "1185/1185 [==============================] - 0s 139us/step - loss: 8.1658e-04 - accuracy: 1.0000\n",
      "509/509 [==============================] - 0s 70us/step\n",
      "Accuracy: 99.80\n",
      "(581, 6)\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "finish 100\n",
      "(1299, 83)\n",
      "(1299, 82) (1299,)\n",
      "Epoch 1/15\n",
      "909/909 [==============================] - 0s 287us/step - loss: 0.3458 - accuracy: 0.9230\n",
      "Epoch 2/15\n",
      "909/909 [==============================] - 0s 138us/step - loss: 0.1568 - accuracy: 0.9538\n",
      "Epoch 3/15\n",
      "909/909 [==============================] - 0s 136us/step - loss: 0.0817 - accuracy: 0.9813\n",
      "Epoch 4/15\n",
      "909/909 [==============================] - 0s 137us/step - loss: 0.0427 - accuracy: 0.9934\n",
      "Epoch 5/15\n",
      "909/909 [==============================] - 0s 138us/step - loss: 0.0232 - accuracy: 0.9967\n",
      "Epoch 6/15\n",
      "909/909 [==============================] - 0s 134us/step - loss: 0.0143 - accuracy: 0.9989\n",
      "Epoch 7/15\n",
      "909/909 [==============================] - 0s 138us/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "909/909 [==============================] - 0s 136us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "909/909 [==============================] - 0s 139us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "909/909 [==============================] - 0s 134us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "909/909 [==============================] - 0s 131us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "909/909 [==============================] - 0s 133us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "909/909 [==============================] - 0s 136us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "909/909 [==============================] - 0s 138us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "909/909 [==============================] - 0s 135us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "390/390 [==============================] - 0s 84us/step\n",
      "Accuracy: 100.00\n",
      "(186, 6)\n"
     ]
    }
   ],
   "source": [
    "CN_intermediate_output = clusterFeatureExtractor(volAndCN_data,CN_freesurfer_Out)\n",
    "MCI_intermediate_output = clusterFeatureExtractor(volAndMCI_data,MCI_freesurfer_Out)\n",
    "AD_intermediate_output = clusterFeatureExtractor(volAndAD_data,AD_freesurfer_Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build my input for clustering\n",
    "layer_name = 'my_layer'\n",
    "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(MCI_vector)\n",
    "print(intermediate_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterInput = MCI_intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusterInput[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means methods"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    ">>> from sklearn.cluster import KMeans\n",
    ">>> import numpy as np\n",
    ">>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "...               [10, 2], [10, 4], [10, 0]])\n",
    ">>> kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    ">>> kmeans.labels_\n",
    "array([1, 1, 1, 0, 0, 0], dtype=int32)\n",
    ">>> kmeans.predict([[0, 0], [12, 3]])\n",
    "array([1, 0], dtype=int32)\n",
    ">>> kmeans.cluster_centers_\n",
    "array([[10.,  2.],\n",
    "       [ 1.,  2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(clusterInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 0, 1, 2, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1,\n",
       "       0, 2, 0, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 0, 2, 1, 0,\n",
       "       1, 0, 2, 0, 0, 2, 2, 1, 0, 1, 2, 1, 1, 0, 2, 0, 0, 1, 1, 1, 1, 2,\n",
       "       1, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 0, 1, 2, 0, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 1, 2, 1, 1, 1, 1, 0, 2, 0,\n",
       "       1, 1, 2, 1, 1, 1, 0, 2, 1, 0, 2, 2, 1, 2, 0, 0, 1, 0, 0, 1, 0, 2,\n",
       "       0, 1, 1, 2, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 0, 1, 2, 2, 2, 1, 0, 0, 1,\n",
       "       0, 1, 2, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 0,\n",
       "       0, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 0, 0, 2,\n",
       "       1, 2, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 2, 1, 1, 1,\n",
       "       1, 1, 0, 2, 1, 2, 1, 0, 2, 0, 1, 1, 1, 2, 1, 0, 2, 1, 1, 2, 2, 2,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 0, 1, 0, 2, 0, 2, 1, 1, 0, 1, 2, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 0, 0, 0, 2, 1, 0, 1, 1, 1, 2, 1,\n",
       "       0, 1, 2, 2, 1, 1, 2, 1, 1, 0, 2, 1, 2, 2, 2, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       2, 2, 1, 1, 1, 0, 2, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       2, 0, 2, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 2, 0, 1, 2, 1, 1, 0, 1, 2, 2, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 0, 0, 2, 1, 1, 1, 2,\n",
       "       1, 2, 2, 2, 0, 0, 1, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the start of draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(csvPath,\"MCI_sne.tsv\"),MCI_vector,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(csvPath,\"all_data.tsv\"),Vector_with_Label[:,0:-1],delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCI_vector,MCI_subject = Convert2FeatureVector(MCI_freesurfer_Out)\n",
    "volner_vector, volner_subject = Convert2FeatureVector(volner)\n",
    "\n",
    "MCI_label = np.ones(302)\n",
    "volner_label = np.zeros(1113)\n",
    "print(MCI_label.shape,volner_label.shape)\n",
    "y = np.concatenate((MCI_label,volner_label))\n",
    "print(y.shape)\n",
    "\n",
    "X = np.concatenate((MCI_vector,volner_vector))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(64,128), random_state=1,max_iter=700)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt(os.path.join(csvPath,'pima-indians-diabetes.data.csv'), delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt(os.path.join(csvPath,'pima-indians-diabetes.data.csv'), delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=15, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the start of draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert pd.Dataframe to feature(np.array) here ## No label here\n",
    "def Convert2FeatureVector(pdFrame):\n",
    "    subject = []\n",
    "    pdFrame = pdFrame.dropna()\n",
    "    pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'] = 1.0 / pdFrame['FS_BrainSeg_Vol_No_Vent_Surf']\n",
    "    X = []\n",
    "    x =[]\n",
    "    weighted_mean_feature_dict = {}\n",
    "    for feature in features:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame[feature_area]).sum() / pdFrame[feature_area].sum()\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            weighted_mean_feature_dict[feature] = (pdFrame[feature] * pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf']).sum() / pdFrame['reverse_FS_BrainSeg_Vol_No_Vent_Surf'].sum()   \n",
    "    variance_feature_dict = {}\n",
    "    for feature in features:\n",
    "        if feature.split('_')[-1] == 'Thck':\n",
    "            feature_area = feature[0:-4] + 'Area'\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[feature_area] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[feature_area].sum() - (np.square(pdFrame[feature_area])).sum() / pdFrame[feature_area].sum()))\n",
    "        if feature.split('_')[-1] == 'Vol':\n",
    "            variance_feature_dict[feature] = np.sqrt((pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"] * np.square(pdFrame[feature] - weighted_mean_feature_dict[feature])).sum() / (pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum() - (np.square(pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"])).sum() / pdFrame[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum()))\n",
    "    for index,row in pdFrame.iterrows():\n",
    "        for feature in features:\n",
    "            x.append((np.float(row[feature]) - weighted_mean_feature_dict[feature]) / variance_feature_dict[feature])\n",
    "#         x.append(row['Subject'])\n",
    "        X.append(x)\n",
    "        subject.append(row['Subject'])\n",
    "        x =[]\n",
    "        if len(X) % 100 == 0:\n",
    "            print(\"finish 100\")\n",
    "    X = np.array(X)\n",
    "    return X, subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(64,100), random_state=1,max_iter=700).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volner_no_Nan = volner.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weighted_mean_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_mean_feature_dict = {}\n",
    "for feature in features:\n",
    "    if feature.split('_')[-1] == 'Thck':\n",
    "        feature_area = feature[0:-4] + 'Area'\n",
    "        weighted_mean_feature_dict[feature] = (volner_no_Nan[feature] * volner_no_Nan[feature_area]).sum() / volner_no_Nan[feature_area].sum()\n",
    "    if feature.split('_')[-1] == 'Vol':\n",
    "        weighted_mean_feature_dict[feature] = (volner_no_Nan[feature] * volner_no_Nan['reverse_FS_BrainSeg_Vol_No_Vent_Surf']).sum() / volner_no_Nan['reverse_FS_BrainSeg_Vol_No_Vent_Surf'].sum()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_feature_dict = {}\n",
    "for feature in features:\n",
    "    if feature.split('_')[-1] == 'Thck':\n",
    "        feature_area = feature[0:-4] + 'Area'\n",
    "        variance_feature_dict[feature] = np.sqrt((volner_no_Nan[feature_area] * np.square(volner_no_Nan[feature] - weighted_mean_feature_dict[feature])).sum() / (volner_no_Nan[feature_area].sum() - (np.square(volner_no_Nan[feature_area])).sum() / volner_no_Nan[feature_area].sum()))\n",
    "    if feature.split('_')[-1] == 'Vol':\n",
    "        variance_feature_dict[feature] = np.sqrt((volner_no_Nan[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"] * np.square(volner_no_Nan[feature] - weighted_mean_feature_dict[feature])).sum() / (volner_no_Nan[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum() - (np.square(volner_no_Nan[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"])).sum() / volner_no_Nan[\"reverse_FS_BrainSeg_Vol_No_Vent_Surf\"].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volner_no_Nan['reverse_FS_BrainSeg_Vol_No_Vent_Surf'] = 1.0 / volner_no_Nan['FS_BrainSeg_Vol_No_Vent_Surf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variance_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "x =[]\n",
    "for index,row in volner_no_Nan.iterrows():\n",
    "    for feature in features:\n",
    "        x.append((np.float(row[feature]) - weighted_mean_feature_dict[feature]) / variance_feature_dict[feature])\n",
    "    X.append(x)\n",
    "    x =[]\n",
    "    if len(X) % 100 == 0:\n",
    "        print(\"finish 100\")\n",
    "X = np.array(X)      \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectFeatures2 = [\"left-wthi-bankssts\",\"left-wthi-caudalanteriorcingulate\",\"left-wthi-caudalmiddlefrontal\",\n",
    "                  \"left-wthi-cuneus\",\"left-wthi-entorhinal\",\"left-wthi-fusiform\",\"left-wthi-inferiorparietal\",\n",
    "                  \"left-wthi-inferiortemporal\",\"left-wthi-isthmuscingulate\",\"left-wthi-lateraloccipital\",\n",
    "                  \"left-wthi-lateralorbitofrontal\",\"left-wthi-lingual\",\"left-wthi-medialorbitofrontal\",\n",
    "                  \"left-wthi-middletemporal\",\"left-wthi-parahippocampal\",\"left-wthi-paracentral\",\n",
    "                  \"left-wthi-parsopercularis\",\"left-wthi-parsorbitalis\",\"left-wthi-parstriangularis\",\n",
    "                  \"left-wthi-pericalcarine\",\"left-wthi-postcentral\",\"left-wthi-posteriorcingulate\",\n",
    "                  \"left-wthi-precentral\",\"left-wthi-precuneus\",\"left-wthi-rostralanteriorcingulate\",\n",
    "                  \"left-wthi-rostralmiddlefrontal\",\"left-wthi-superiorfrontal\",\"left-wthi-superiorparietal\",\n",
    "                  \"left-wthi-superiortemporal\",\"left-wthi-supramarginal\",\"left-wthi-frontalpole\",\n",
    "                  \"left-wthi-temporalpole\",\"left-wthi-transversetemporal\",\"left-wthi-insula\",\"right-wthi-bankssts\",\n",
    "                  \"right-wthi-caudalanteriorcingulate\",\"right-wthi-caudalmiddlefrontal\",\"right-wthi-cuneus\",\n",
    "                  \"right-wthi-entorhinal\",\"right-wthi-fusiform\",\"right-wthi-inferiorparietal\",\n",
    "                  \"right-wthi-inferiortemporal\",\"right-wthi-isthmuscingulate\",\"right-wthi-lateraloccipital\",\n",
    "                  \"right-wthi-lateralorbitofrontal\",\"right-wthi-lingual\",\"right-wthi-medialorbitofrontal\",\n",
    "                  \"right-wthi-middletemporal\",\"right-wthi-parahippocampal\",\"right-wthi-paracentral\",\n",
    "                  \"right-wthi-parsopercularis\",\"right-wthi-parsorbitalis\",\"right-wthi-parstriangularis\",\n",
    "                  \"right-wthi-pericalcarine\",\"right-wthi-postcentral\",\"right-wthi-posteriorcingulate\",\n",
    "                  \"right-wthi-precentral\",\"right-wthi-precuneus\",\"right-wthi-rostralanteriorcingulate\",\n",
    "                  \"right-wthi-rostralmiddlefrontal\",\"right-wthi-superiorfrontal\",\"right-wthi-superiorparietal\",\n",
    "                  \"right-wthi-superiortemporal\",\"right-wthi-supramarginal\",\"right-wthi-frontalpole\",\n",
    "                  \"right-wthi-temporalpole\",\"right-wthi-transversetemporal\",\"right-wthi-insula\",\n",
    "                  \"right-svol-Thalamus\",\"right-svol-Caudate\",\"right-svol-Putamen\",\"right-svol-Pallidum\",\n",
    "                  \"right-svol-Hippocampus\",\"right-svol-Amygdala\",\"right-svol-Accumbens\",\"left-svol-Thalamus\",\n",
    "                  \"left-svol-Caudate\",\"left-svol-Putamen\",\"left-svol-Pallidum\",\"left-svol-Hippocampus\",\n",
    "                  \"left-svol-Amygdala\",\"left-svol-Accumbens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the jwt token (run bl login to create this file)\n",
    "jwt_file = open(os.environ['HOME']+'/.config/brainlife.io/.jwt', mode='r')\n",
    "jwt = jwt_file.read()\n",
    "#query datasets records\n",
    "find = { \n",
    "    '_group_id': '69', #see project detail page \n",
    "    'service': 'brainlife/app-freesurfer', \n",
    "    #'service_branch': '0.0.5',\n",
    "    'status': 'finished' }\n",
    "params = { \n",
    "    'limit': 100, \n",
    "    'select': 'config._inputs.meta', #we just want product and meta\n",
    "    'find': json.JSONEncoder().encode(find) }\n",
    "res = requests.get('https://brainlife.io/api/amaretti/task', params=params, headers={'Authorization': 'Bearer '+jwt})\n",
    "if res.status_code != 200:\n",
    "    raise Exception(\"failed to download datasets list:\"+res.status_code)\n",
    "tasks = res.json()[\"tasks\"]\n",
    "for task in tasks:\n",
    "    taskid=task[\"_id\"]\n",
    "    subject=task[\"config\"][\"_inputs\"][0][\"meta\"][\"subject\"]\n",
    "    print(taskid, subject)\n",
    "    url = 'https://brainlife.io/api/amaretti/task/download/'+taskid+'/freesurfer/output/stats?at='+jwt\n",
    "    res = requests.get(url, allow_redirects=True)\n",
    "    open(subject+'.tar.gz', 'wb').write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://brainlife.io/api/amaretti/resource',headers={'Authorization': 'Bearer '+jwt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This verison is for all volume feature\n",
    "selectFeatures1 = [\"left-vol-bankssts\",\"left-vol-caudalanteriorcingulate\",\"left-vol-caudalmiddlefrontal\",\n",
    "                  \"left-vol-cuneus\",\"left-vol-entorhinal\",\"left-vol-fusiform\",\"left-vol-inferiorparietal\",\n",
    "                  \"left-vol-inferiortemporal\",\"left-vol-isthmuscingulate\",\"left-vol-lateraloccipital\",\n",
    "                  \"left-vol-lateralorbitofrontal\",\"left-vol-lingual\",\"left-vol-medialorbitofrontal\",\n",
    "                  \"left-vol-middletemporal\",\"left-vol-parahippocampal\",\"left-vol-paracentral\",\n",
    "                  \"left-vol-parsopercularis\",\"left-vol-parsorbitalis\",\"left-vol-parstriangularis\",\n",
    "                  \"left-vol-pericalcarine\",\"left-vol-postcentral\",\"left-vol-posteriorcingulate\",\n",
    "                  \"left-vol-precentral\",\"left-vol-precuneus\",\"left-vol-rostralanteriorcingulate\",\n",
    "                  \"left-vol-rostralmiddlefrontal\",\"left-vol-superiorfrontal\",\"left-vol-superiorparietal\",\n",
    "                  \"left-vol-superiortemporal\",\"left-vol-supramarginal\",\"left-vol-frontalpole\",\n",
    "                  \"left-vol-temporalpole\",\"left-vol-transversetemporal\",\"left-vol-insula\",\"right-vol-bankssts\",\n",
    "                  \"right-vol-caudalanteriorcingulate\",\"right-vol-caudalmiddlefrontal\",\"right-vol-cuneus\",\n",
    "                  \"right-vol-entorhinal\",\"right-vol-fusiform\",\"right-vol-inferiorparietal\",\n",
    "                  \"right-vol-inferiortemporal\",\"right-vol-isthmuscingulate\",\"right-vol-lateraloccipital\",\n",
    "                  \"right-vol-lateralorbitofrontal\",\"right-vol-lingual\",\"right-vol-medialorbitofrontal\",\n",
    "                  \"right-vol-middletemporal\",\"right-vol-parahippocampal\",\"right-vol-paracentral\",\n",
    "                  \"right-vol-parsopercularis\",\"right-vol-parsorbitalis\",\"right-vol-parstriangularis\",\n",
    "                  \"right-vol-pericalcarine\",\"right-vol-postcentral\",\"right-vol-posteriorcingulate\",\n",
    "                  \"right-vol-precentral\",\"right-vol-precuneus\",\"right-vol-rostralanteriorcingulate\",\n",
    "                  \"right-vol-rostralmiddlefrontal\",\"right-vol-superiorfrontal\",\"right-vol-superiorparietal\",\n",
    "                  \"right-vol-superiortemporal\",\"right-vol-supramarginal\",\"right-vol-frontalpole\",\n",
    "                  \"right-vol-temporalpole\",\"right-vol-transversetemporal\",\"right-vol-insula\",\n",
    "                  \"right-svol-Thalamus\",\"right-svol-Caudate\",\"right-svol-Putamen\",\"right-svol-Pallidum\",\n",
    "                  \"right-svol-Hippocampus\",\"right-svol-Amygdala\",\"right-svol-Accumbens\",\"left-svol-Thalamus\",\n",
    "                  \"left-svol-Caudate\",\"left-svol-Putamen\",\"left-svol-Pallidum\",\"left-svol-Hippocampus\",\n",
    "                  \"left-svol-Amygdala\",\"left-svol-Accumbens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(type(x))\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volner_tensor = torch.tensor(volner_vector)\n",
    "volner_tensor2 = torch.from_numpy(volner_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
